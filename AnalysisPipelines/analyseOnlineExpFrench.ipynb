{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c3f2a6b",
   "metadata": {},
   "source": [
    "# MathsSim experiment analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc0555b",
   "metadata": {},
   "source": [
    "Analysis of the data collected with the MathsSim online experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d388a6",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7e26f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", UserWarning)\n",
    "warnings.simplefilter('ignore', FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b8c792",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import seaborn as sns\n",
    "from statannotations.Annotator import Annotator # https://github.com/trevismd/statannotations/tree/master\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.weightstats import ttest_ind\n",
    "from statsmodels.stats.anova import anova_lm\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd as tukeyhsd\n",
    "from scipy import stats\n",
    "from scipy.spatial import distance\n",
    "from scipy.stats import rankdata\n",
    "from scipy.optimize import curve_fit\n",
    "from scikit_posthocs import posthoc_dunn\n",
    "from sklearn.metrics import pairwise_distances \n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import ast\n",
    "from tqdm.notebook import tqdm\n",
    "from IPython.display import display, Markdown\n",
    "import os\n",
    "import subprocess\n",
    "from shutil import which"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96cca2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "custom = {'grid.color': '.8', 'axes.edgecolor': 'black', 'axes.spines.top': False, 'axes.spines.right': False, 'figure.figsize': (11.7,8.27), 'font.size':11, 'font.family': 'Arial', 'font.sans-serif': 'Arial'}\n",
    "sns.set_theme(style=\"whitegrid\", rc=custom)\n",
    "plt.rcParams['svg.fonttype'] = 'none'\n",
    "figWidth = 7.677165 # 19.5cm pour PLOS\n",
    "ratio = 8.27/11.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71c80bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def rankOLS(y,X, **kws):\n",
    "    X = np.array(X)\n",
    "    if len(np.shape(X)) == 1:\n",
    "        X = np.reshape(X, (1,len(X)))\n",
    "    rankx = np.transpose(np.array([rankdata(x) for x in X]))\n",
    "    ranky = rankdata(y)\n",
    "    rankxconst = sm.add_constant(rankx)\n",
    "    model = sm.OLS(endog=ranky, exog=rankxconst, **kws)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0794023b",
   "metadata": {},
   "outputs": [],
   "source": [
    "subData = pd.read_csv('../Data/subDataFrench.csv', encoding='utf-8', index_col='SubID')\n",
    "expData = pd.read_csv('../Data/expDataFrench.csv', encoding='utf-8')\n",
    "stimData = pd.read_csv('../Data/pairSim/French/pairSim_50_maths.csv', encoding='utf-8', index_col='PairID')\n",
    "vocData = pd.read_csv('../Data/finalVocab_French.csv', encoding='utf-8', index_col='word',\n",
    "                      converters={'grammaticalForm': ast.literal_eval}, dtype={'mathsFrequency': float, 'nonMathsFrequency': float})\n",
    "translationData = pd.read_csv('../Data/FrenchEnglish.csv', encoding='utf-8', index_col='French')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029e7f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "EdLevelToId = {'Bac+2':5, 'Bac+5 (master)':8, 'Bac+3 (licence)':6, 'Bac+4':7, \n",
    "                'Bac':3, 'Primaire':0, 'Bac+1':4, 'Bac+8 (doctorat)':9, 'Lycée':2, 'Collège':1}\n",
    "edLevelOrder = ['Primary school', 'Medium school', 'High school', 'High school diploma', '1st year of college', '2nd year of college (bachelor)', '3rd year of college (licence)', '4th year of college', 'Graduate (master)', 'Graduate (PhD)']\n",
    "edLevelOrderTwoLines = ['Primary school', 'Medium school', 'High school', 'High school diploma', '1st year of college', '2nd year of college\\n(bachelor)', '3rd year of college\\n(licence)', '4th year of college', 'Graduate\\n(master)', 'Graduate\\n(PhD)']\n",
    "wordLevelOrder = ['Primary school', '6-7th grade', '8-9th grade', '10th grade', '11-12th grade', 'Bachelor', 'Licence', 'Master']\n",
    "subData['EdLevelId'] = [EdLevelToId[l] for l in subData.EdLevel]\n",
    "subData = subData[['Sex', 'Age', 'Major', 'EdLevelId', 'EdLevel', 'SelfAssessment', 'StimLevel']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f143042",
   "metadata": {},
   "outputs": [],
   "source": [
    "# translate labels into English\n",
    "EdLevel_FrToEn = {}\n",
    "for i, x in enumerate(['Primaire', 'Collège', 'Lycée', 'Bac', 'Bac+1', 'Bac+2', 'Bac+3 (licence)', 'Bac+4', 'Bac+5 (master)', 'Bac+8 (doctorat)']):\n",
    "    EdLevel_FrToEn[x] = edLevelOrder[i]\n",
    "\n",
    "WordLevel_FrToEn = {}\n",
    "for i, x in enumerate(['primaire', '6e-5e', '4e-3e', '2nd', '1ere-Tale', 'prépa', 'licence', 'master']):\n",
    "    WordLevel_FrToEn[x] = wordLevelOrder[i]\n",
    "\n",
    "vocData['levelName'] = [WordLevel_FrToEn[x.levelName] for x in vocData.itertuples()]\n",
    "subData['EdLevel'] = [EdLevel_FrToEn[x.EdLevel] for x in subData.itertuples()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d15ce7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(word):\n",
    "    translation = translationData.loc[word].English\n",
    "    if translation == 'NONE':\n",
    "        raise IndexError\n",
    "    return translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dca557b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exclude participants\n",
    "expData = expData.loc[expData.SubID != '3u1h1p0p05'].copy()\n",
    "subData.drop(index='3u1h1p0p05', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190eec40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exclude judgements for pairs of level > given by participants of ed level bac\n",
    "tmp = expData.join(subData, on=\"SubID\").join(stimData, on='Question')\n",
    "toDelete = tmp[(tmp.EdLevel == 'Bac') & (tmp.Level >= 5)].index\n",
    "expData.drop(index=toDelete, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959d4d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = expData.join(subData, on=\"SubID\").join(stimData, on=\"Question\").join(vocData, on=\"Question\")\n",
    "df.rename(columns={'StimLevel': 'SubLevel', 'Level': 'PairLevel', 'levelId': 'WordLevelId', 'levelName': 'WordLevelName'}, inplace=True)\n",
    "df.drop(['metaMaths', 'tooPolysemic', 'grammaticalForm', 'mathsFrequency', 'nonMathsFrequency'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae68ac5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5728c53",
   "metadata": {},
   "source": [
    "## Demographic data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb02d30",
   "metadata": {},
   "source": [
    "### Data summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2964e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "subData['Sex'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e0b592",
   "metadata": {},
   "outputs": [],
   "source": [
    "subData['Age'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c117db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "subData['Major'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1295b808",
   "metadata": {},
   "outputs": [],
   "source": [
    "subData['EdLevel'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c223d1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "subData['SelfAssessment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00db1052",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(subData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b5d272",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.spearmanr(subData.SelfAssessment, subData.EdLevelId)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f308ae",
   "metadata": {},
   "source": [
    "### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6d62c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "majorsOrder = [\"Mathematics\", \"Statistics\", \"Economics\", \"Engineering\", \"Natural Science\", \"Health and Life Science\", \"Psychology\", \"Humanities\", \"Law\", \"None\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a559544",
   "metadata": {},
   "outputs": [],
   "source": [
    "# distribution of education level\n",
    "ax = sns.countplot(data=subData, x=\"EdLevel\", color=sns.color_palette()[0], order=edLevelOrder)\n",
    "ax.set(xlabel=\"Last classes followed in maths\")\n",
    "ax.tick_params(axis='x', rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83b86d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# distribution of self-assessed maths level\n",
    "ax = sns.countplot(data=subData, x=\"SelfAssessment\", color=sns.color_palette()[0])\n",
    "ax.set(xlabel=\"Self-assessed maths-level\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd7b726",
   "metadata": {},
   "outputs": [],
   "source": [
    "# distribution of majors\n",
    "ax = sns.countplot(data=subData, x=\"Major\", color=sns.color_palette()[0], order=majorsOrder)\n",
    "ax.set(xlabel=\"College Major\")\n",
    "ax.tick_params(axis='x', rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2717f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# self-assessed maths level against education level\n",
    "ax = sns.barplot(data=subData, x=\"EdLevel\", y=\"SelfAssessment\", errorbar=\"sd\", color=sns.color_palette()[0],\n",
    "                order=edLevelOrder)\n",
    "ax.set(xlabel=\"Last classes followed in maths\", ylabel=\"Self-assessed maths level\",\n",
    "       title=\"Self-assessed maths level against last classes followed in maths\",\n",
    "       ylim=[0,10])\n",
    "ax.tick_params(axis='x', rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad44bde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# self-assessed maths level against major\n",
    "ax = sns.barplot(data=subData, x=\"Major\", y=\"SelfAssessment\", errorbar=\"sd\", color=sns.color_palette()[0],\n",
    "                order=majorsOrder)\n",
    "ax.set(xlabel=\"College Major\", ylabel=\"Self-assessed maths level\", title=\"Self-assessed maths level against college major\",\n",
    "       ylim=[0,10])\n",
    "ax.tick_params(axis='x', rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494665e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# self-assessed maths level against age\n",
    "ax = sns.barplot(data=subData, x=\"Age\", y=\"SelfAssessment\", errorbar=\"sd\", color=sns.color_palette()[0],\n",
    "                order=[\"18-25\", \"25-40\", \"40-60\", \"60-more\"])\n",
    "ax.set(xlabel=\"Age\", ylabel=\"Self-assessed maths level\", title=\"Self-assessed maths level against age\",\n",
    "       ylim=[0,10])\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "366a822d",
   "metadata": {},
   "source": [
    "## Voc knowledge analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcdce29c",
   "metadata": {},
   "source": [
    "Questions:\n",
    "- Overall, is our classification of words correct? Does it fit with the actual education of participants?\n",
    "- Are some words misclassified?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cda850b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data\n",
    "vData = df.loc[df.Trial == 'VocKnowledge'].copy()\n",
    "vData.drop(['Trial', 'RT', 'PresentationOrder', 'Training', 'SubLevel', 'word1', 'word2', 'PairLevel', 'Similarity'], \n",
    "           axis=1, inplace=True)\n",
    "vData['Answer'] = vData.Answer.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d36ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "vData"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d74719",
   "metadata": {},
   "source": [
    "### Analysis of the average knowledge for each word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6e0f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "meanKnowledge = vData.groupby('Question').mean(numeric_only=True)\n",
    "meanKnowledge['Count'] = vData.value_counts('Question')\n",
    "meanKnowledge['WordLevelName'] = meanKnowledge.join(vocData, on='Question').levelName\n",
    "meanKnowledge['STD'] = [np.std(vData[vData.Question == x].Answer) for x in meanKnowledge.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e6daae",
   "metadata": {},
   "outputs": [],
   "source": [
    "meanKnowledge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7bcdc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "saveVoc = False\n",
    "\n",
    "if saveVoc:\n",
    "    meanKnowledge.to_excel('vocAnalyses/vocKnowledge.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77a0272",
   "metadata": {},
   "outputs": [],
   "source": [
    "meanKnowledge.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49870ec9",
   "metadata": {},
   "source": [
    "#### Relation between average knowledge and proposed classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe8362d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spearman's rank correlation analysis\n",
    "res = stats.spearmanr(meanKnowledge.WordLevelId, meanKnowledge.Answer)\n",
    "display(Markdown(rf\"Spearman's $r_s$ coefficient: {res.statistic**2:.3f} (p = {res.pvalue:.2e})\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8fa82d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.pointplot(meanKnowledge, x=\"WordLevelName\", y=\"Answer\", errorbar='sd',\n",
    "                  order=wordLevelOrder)\n",
    "ax.set(ylim=[-0.1,8.1], yticks=[i for i in range(9)],\n",
    "       xlabel=\"Estimated level of acquisition\", ylabel=\"Mean knowledge rating per word (from 0 to 8)\")\n",
    "ax.text(0.5, 0.5, f\"Spearman's $r_s$ = {res.statistic:.2f}\\np = {res.pvalue:.2e}\", \n",
    "        horizontalalignment='center', verticalalignment='center', bbox={'edgecolor':'black', 'facecolor':'none'})\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8877cdfe",
   "metadata": {},
   "source": [
    "#### Distribution of average knowledge across words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a21574",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.violinplot(meanKnowledge, x=\"Answer\", y=\"WordLevelName\", cut=0, scale='count', \n",
    "                    order=wordLevelOrder, color=sns.color_palette()[0])\n",
    "b = set(list(ax.get_children()))\n",
    "ax = sns.pointplot(meanKnowledge, x=\"Answer\", y=\"WordLevelName\", errorbar=None, \n",
    "              order=wordLevelOrder, color=sns.color_palette()[5], markers='x', ax=ax)\n",
    "f = set(list(ax.get_children()))-b\n",
    "for e in f:\n",
    "    e.set_zorder(100)\n",
    "ax.set(xlim=[-0.1,8.1], xticks=[i for i in range(9)],\n",
    "       xlabel=\"Mean knowledge rating per word (from 0 to 8)\", ylabel=\"Estimated level of acquisition\")\n",
    "for level, levelData in meanKnowledge.groupby('WordLevelId'):\n",
    "    ax.text(0.5,level,f\"n = {len(levelData)}\", horizontalalignment='center')\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced622f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.displot(meanKnowledge, x=\"Answer\", col=\"WordLevelName\", kind=\"kde\",\n",
    "               col_order=wordLevelOrder, col_wrap=4, facet_kws={'sharey':False})\n",
    "g.set_axis_labels(\"Mean knowledge rating per word (from 0 to 8)\", \"Density\")\n",
    "g.set_titles(col_template=\"Estimated level of acquisition = {col_name}\")\n",
    "g.set(xlim=(-0.1, 8.1), xticks=[i for i in range(9)])\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f205c4bb",
   "metadata": {},
   "source": [
    "### Variation of the average knowledge with self-reported maths education"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85550ed",
   "metadata": {},
   "source": [
    "#### Redo the as above for each self-report maths education level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca023e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "meanKnowledgeLevelDep = vData.groupby(['Question', 'EdLevel']).mean(numeric_only=True)\n",
    "meanKnowledgeLevelDep['Count'] = vData.groupby(['Question', 'EdLevel']).count().SubID\n",
    "meanKnowledgeLevelDep['WordLevelName'] = meanKnowledgeLevelDep.join(vocData, on='Question').levelName\n",
    "for val in ['Question', 'EdLevel']:\n",
    "    meanKnowledgeLevelDep[val] = meanKnowledgeLevelDep.index.get_level_values(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c81e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "meanKnowledgeLevelDep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b6421d",
   "metadata": {},
   "source": [
    "##### Relation between average knowledge and proposed classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f4261f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# article fig\n",
    "ax= sns.pointplot(meanKnowledgeLevelDep, y=\"EdLevel\", x=\"Answer\", hue=\"WordLevelName\", dodge=True, \n",
    "                  order=edLevelOrder, hue_order=wordLevelOrder, palette=['#1b9e77','#d95f02','#7570b3','#e7298a','#66a61e','#e6ab02','#a6761d','#666666'])\n",
    "ax.set(xlabel=\"\", ylabel=\"\")\n",
    "ax.set_yticklabels(labels=edLevelOrderTwoLines)\n",
    "leg = ax.legend(title=\"Word grade\", loc='center right', bbox_to_anchor=[1,.5])\n",
    "leg.remove()\n",
    "#ax.text(ax.get_xlim()[0], ax.get_ylim()[1]+.2, \"Familiarity rating\", size=12, horizontalalignment=\"center\", va=\"bottom\")\n",
    "#ax.text(ax.get_xlim()[1]+.2, ax.get_ylim()[0], \"Participant education level\", size=12, horizontalalignment=\"left\", va=\"center\")\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(figWidth/1.4, figWidth*ratio)\n",
    "plt.grid(axis='y')\n",
    "for item in ([ax.title, ax.xaxis.label, ax.yaxis.label] +\n",
    "             ax.get_xticklabels() + ax.get_yticklabels()):\n",
    "    item.set_fontsize(14)\n",
    "#plt.tight_layout()\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0098065",
   "metadata": {},
   "outputs": [],
   "source": [
    "dff = vData.join(vocData, on='Question', rsuffix=\"_r\")\n",
    "dff['WordLevelId'] = (lambda x: (x-np.mean(x))/np.std(x))((lambda y: rankdata(y))(dff['WordLevelId']))\n",
    "dff['mathsFrequency'] = (lambda x: (x-np.mean(x))/np.std(x))((lambda y: rankdata(y))((lambda x: np.log10(x)+6)(dff['mathsFrequency'])))\n",
    "dff['EdLevelId'] = (lambda x: (x-np.mean(x))/np.std(x))((lambda y: rankdata(y))(dff['EdLevelId']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f267f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = smf.mixedlm(\"Answer ~ WordLevelId * mathsFrequency * EdLevelId\", dff, groups=dff['SubID'])\n",
    "results = model.fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea1235d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ols('Answer ~ WordLevelId * EdLevelId', data=dff)\n",
    "results = model.fit()\n",
    "results.summary2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d4345a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ols('Answer ~ WordLevelId * mathsFrequency * EdLevelId', data=dff)\n",
    "results = model.fit()\n",
    "results.summary2()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73d1953",
   "metadata": {},
   "source": [
    "##### Distribution of average knowledge across words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19fecf95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotBox(data, x=None, y=None, **kws):\n",
    "    ax = sns.boxplot(data, x=x, y=y, #cut=0, scale='count',\n",
    "                    order=wordLevelOrder, color='#f768a1')\n",
    "    b = set(list(ax.get_children()))\n",
    "    ax = sns.pointplot(data, x=x, y=y, errorbar=None, \n",
    "                  order=wordLevelOrder, color='#c51b8a', markers='x', ax=ax)\n",
    "    f = set(list(ax.get_children()))-b\n",
    "    for e in f:\n",
    "        e.set_zorder(100)\n",
    "    # for level, levelData in data.groupby('WordLevelId'):\n",
    "    #     ax.text(level, 0.5, f\"n = {len(levelData)}\", horizontalalignment='center', verticalalignment='center', color='#7a0177', size=11, rotation=30)\n",
    "    # ax.text(7, 7, f\"N = {len(data)}\", bbox={'edgecolor':'black', 'facecolor':'white'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df49e3f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(meanKnowledgeLevelDep, col=\"EdLevel\", col_wrap=2, col_order=edLevelOrder, height=5, aspect=8, sharex=True, sharey=True, despine=False)\n",
    "g.figure.subplots_adjust(wspace=0, hspace=0)\n",
    "g.map_dataframe(plotBox, y=\"Answer\", x=\"WordLevelName\")\n",
    "g.set(ylim=[-0.1,8.1], yticks=[i for i in range(9)],\n",
    "      ylabel=\"Mean familiarity\\nrating per word\\n(across part.)\", xlabel=\"Words' estimated\\nlevel of acquisition\")\n",
    "g.set_xticklabels(labels=wordLevelOrder, rotation=45, ha='right')\n",
    "g.set_titles(col_template=\"{col_name}\")\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(.8*figWidth, 8.1653543)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae3add1",
   "metadata": {},
   "source": [
    "#### Knowledge of every individual word as a function of self-reported level"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e184981",
   "metadata": {},
   "source": [
    "Can we find some swing words that dramatically change from unknown to known as education improves?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7142a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x, L ,x0, k, b):\n",
    "    y = L / (1 + np.exp(-k*(x-x0))) + b\n",
    "    return (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e0ae80",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval = False\n",
    "\n",
    "if eval:\n",
    "    \n",
    "    with PdfPages('SingleWordKnowledge.pdf') as pdf:\n",
    "        for word, wData in vData.groupby('Question'):\n",
    "            \n",
    "            # plot data points\n",
    "            ax = sns.pointplot(wData, x='EdLevelId', y='Answer', errorbar='sd', join=False,\n",
    "                               order=[i for i in range(len(edLevelOrder))])\n",
    "            \n",
    "            # fit sigmoid\n",
    "            p0 = [np.max(wData.Answer), np.median(wData.EdLevelId), 1, np.min(wData.Answer)]\n",
    "            popt, pcov = curve_fit(sigmoid, wData.EdLevelId, wData.Answer, p0, method='dogbox', maxfev=10000)\n",
    "            \n",
    "            # compute R^2 for the fit\n",
    "            residuals = wData.Answer - sigmoid(wData.EdLevelId, *popt)\n",
    "            ss_res = np.sum(residuals**2)\n",
    "            ss_tot = np.sum((wData.Answer-np.mean(wData.Answer))**2)\n",
    "            r_squared = 1 - (ss_res / ss_tot)\n",
    "            colour = sns.color_palette[3] if r_squared >= 0.7 else 'black'\n",
    "            \n",
    "            # plot fitted sigmoid\n",
    "            t = np.arange(0,9,0.01)\n",
    "            plt.plot(t, [sigmoid(x, *popt) for x in t])\n",
    "            \n",
    "            # cosmetics\n",
    "            ax.set(title=f\"Word: {word} ({vData.loc[vData.Question == word].WordLevelName.unique()[0]})\", \n",
    "                   xlabel=\"Reported education level\", ylabel=\"Knowledge rating (from 0 to 8)\", \n",
    "                   ylim=[-0.1,8.1], xticks=[i for i in range(10)], xticklabels=edLevelOrder)\n",
    "            ax.tick_params(axis='x', rotation=45)\n",
    "            ax.text(0.5, 7.5, f\"N = {len(wData)}\", horizontalalignment='center')\n",
    "            ax.text(8.5, 0.5, f\"Fit $R^2$ = {r_squared:.2f}\",\n",
    "                    horizontalalignment='center', verticalalignment='center', \n",
    "                    color=colour, bbox={'edgecolor':'black', 'facecolor':'none'})\n",
    "            \n",
    "            pdf.savefig()\n",
    "            plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba396bb",
   "metadata": {},
   "source": [
    "### Participant analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d7c990",
   "metadata": {},
   "outputs": [],
   "source": [
    "vDataPerSub = vData.groupby('SubID').mean(numeric_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6aa2809",
   "metadata": {},
   "source": [
    "What is the mean knowledge of a given participant?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463a87ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.kdeplot(vDataPerSub, x=\"Answer\")\n",
    "ax.set(xlim=[-0.1,8.1], xticks=[i for i in range(9)],\n",
    "       xlabel=\"Mean knowledge rating per participant (from 0 to 8)\")\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7487231a",
   "metadata": {},
   "source": [
    " Is it correlated with its self-report education and maths level?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a58249",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = stats.spearmanr(vDataPerSub.EdLevelId, vDataPerSub.Answer)\n",
    "display(Markdown(rf\"Spearman's $r_s$ coefficient: {res.statistic:.2f} (p = {res.pvalue:.2e})\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5868e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.pointplot(vDataPerSub, x=\"EdLevelId\", y=\"Answer\", errorbar='sd')\n",
    "ax.set(ylim=[-0.1,8.1], yticks=[i for i in range(9)],\n",
    "       xlabel=\"Reported education level\", ylabel=\"Mean knowledge rating per participant (from 0 to 8)\",\n",
    "       xticks=[i for i in range(len(edLevelOrder))], xticklabels=edLevelOrder)\n",
    "ax.tick_params(axis='x', rotation=45)\n",
    "ax.text(8.5, 0.5, f\"Spearman's $r_s$ = {res.statistic:.2f}\\nN = {len(vDataPerSub)}\\np = {res.pvalue:.2e}\", \n",
    "        horizontalalignment='center', verticalalignment='center', bbox={'edgecolor':'black', 'facecolor':'none'})\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b9540f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(vDataPerSub.SelfAssessment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf7cee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = stats.spearmanr(vDataPerSub.SelfAssessment, vDataPerSub.Answer)\n",
    "display(Markdown(rf\"Spearman's $r_s$ coefficient: {res.statistic:.2f} (p = {res.pvalue:.2e})\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4e96f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.pointplot(vDataPerSub, x=\"SelfAssessment\", y=\"Answer\", errorbar='sd')\n",
    "ax.set(ylim=[-0.1,8.1], yticks=[i for i in range(9)], xticks=[i for i in range(10)],\n",
    "       xlabel=\"Self-assessed maths level (from 1 to 10)\", ylabel=\"Mean knowledge rating per participant (from 0 to 8)\")\n",
    "ax.text(8.5, 0.5, f\"Spearman's $r_s$ = {res.statistic:.2f}\\np = {res.pvalue:.2e}\", \n",
    "        horizontalalignment='center', verticalalignment='center', bbox={'edgecolor':'black', 'facecolor':'none'})\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f11a62",
   "metadata": {},
   "source": [
    "### Item Response Theory on word knowledge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1dcda15",
   "metadata": {},
   "source": [
    "#### IRT by dichotomising the response variable (using R)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f34d54",
   "metadata": {},
   "source": [
    "##### Just IRT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5f19a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "IRTdata = vData.groupby([\"SubID\", \"Question\"]).min().reset_index().pivot(index=\"SubID\", columns=\"Question\", values=\"Answer\").applymap(lambda x: 0 if x <= 3 else 1, na_action='ignore')\n",
    "\n",
    "toDrop = []\n",
    "\n",
    "for col in IRTdata.columns:\n",
    "    val = [x for x in IRTdata[col].unique() if not np.isnan(x)]\n",
    "    if len(val) <= 1:\n",
    "        toDrop.append(col)\n",
    "\n",
    "IRTdata.drop(columns=toDrop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68fd7436",
   "metadata": {},
   "outputs": [],
   "source": [
    "runIRT = False\n",
    "\n",
    "if runIRT:\n",
    "\n",
    "    IRTdata.to_csv(\"vocAnalyses/IRTData.csv\")\n",
    "\n",
    "    rscript = os.path.normpath(os.path.join(os.getcwd(), 'IRT.R'))\n",
    "    ret = subprocess.run([which('Rscript'), rscript])\n",
    "    assert(ret.returncode == 0)\n",
    "\n",
    "    IRTitems = pd.read_csv(\"IRTitems.csv\", encoding='utf-8')\n",
    "    IRTsubjects = pd.read_csv(\"IRTsubjects.csv\", encoding='utf-8')\n",
    "\n",
    "    IRTsubjects['SubID'] = IRTdata.index\n",
    "    IRTsubjects.rename(columns={'F1':'Theta'}, inplace=True)\n",
    "    IRTsubjects.drop(columns='Unnamed: 0', inplace=True)\n",
    "\n",
    "    IRTitems.drop(columns=['means', 'F1'], inplace=True)\n",
    "    IRTitems.rename(columns={'Unnamed: 0': 'Question'}, inplace=True)\n",
    "    IRTitems.set_index('Question', inplace=True)\n",
    "    IRTitems.rename(index={'X..mathbb.C..': '$\\\\mathbb{C}$', 'X..mathbb.N..': '$\\\\mathbb{N}$', 'X..mathbb.Q..': '$\\\\mathbb{Q}$', 'X..mathbb.R..': '$\\\\mathbb{R}$', 'X..mathbb.Z..': '$\\\\mathbb{Z}$', 'X..pi.': '$\\\\pi$'}, inplace=True)\n",
    "    IRTitems.rename(columns={x: x.split('.')[-1] for x in IRTitems.columns}, inplace=True)\n",
    "\n",
    "    IRTitems.to_csv('IRTitems.csv', encoding='utf-8')\n",
    "    IRTsubjects.to_csv('IRTsubjects.csv', encoding='utf-8',  index=False)\n",
    "\n",
    "else:\n",
    "    \n",
    "    IRTitems = pd.read_csv(\"IRTitems.csv\", encoding='utf-8')\n",
    "    IRTsubjects = pd.read_csv(\"IRTsubjects.csv\", encoding='utf-8')\n",
    "    # a -> discrimination\n",
    "    # b -> difficulty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c99722e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# difficulty parameter\n",
    "IRTitems.b.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46eacb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# discrimination parameter\n",
    "IRTitems.a.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d727c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.histplot(IRTsubjects, x='Theta', binwidth=.1)\n",
    "ax.vlines(x=np.mean(IRTsubjects.Theta), ymin=0, ymax=60, colors=sns.color_palette()[1])\n",
    "ax.set(xlabel=\"Theta\")\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3c3f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check rank correlation between IRT estimated theta and participants' reported education level\n",
    "IRTSubLevel = subData.join(IRTsubjects.set_index('SubID'), on='SubID')\n",
    "model = rankOLS(IRTSubLevel.Theta, [IRTSubLevel.EdLevelId, IRTSubLevel.SelfAssessment])\n",
    "result = model.fit()\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eddfa98",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = rankOLS(IRTSubLevel.Theta, IRTSubLevel.EdLevelId)\n",
    "result = model.fit()\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ecc6615",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.regplot(IRTSubLevel, x=\"EdLevelId\", y=\"Theta\", \n",
    "                 line_kws={'color': sns.color_palette()[1]})\n",
    "ax.set(xlabel=\"Participant education\", ylabel=\"IRT estimated latent ability\")\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7910e950",
   "metadata": {},
   "outputs": [],
   "source": [
    "q90A = np.percentile(IRTitems.a, 90)\n",
    "q5B, q95B = np.percentile(IRTitems.b, [5, 95])\n",
    "curatedIRTitems = IRTitems.loc[(IRTitems.a <= q90A) & (IRTitems.b <= q95B) & (IRTitems.b >= q5B)]\n",
    "curatedIRTitems = curatedIRTitems.join(meanKnowledge, on='Question')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a1143f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(curatedIRTitems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d75f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(IRTitems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f96068a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(curatedIRTitems)/len(IRTitems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce074cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.histplot(curatedIRTitems, x='a', binwidth=.1)\n",
    "ax.set(xlabel=\"Discrimination param\")\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5632d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.histplot(curatedIRTitems, x='b', binwidth=.1)\n",
    "ax.set(xlabel=\"Difficulty param\")\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4da3348",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot individual IRT\n",
    "eval = False\n",
    "\n",
    "if eval:\n",
    "    \n",
    "    dat = vData.join(IRTsubjects.set_index('SubID'), on='SubID').join(curatedIRTitems.set_index('Question'), on='Question', rsuffix=\"_bis\")\n",
    "    dat['DichoAnswers'] = [0 if x <= 3 else 1 for x in dat.Answer]\n",
    "\n",
    "    kept = list(curatedIRTitems.Question)\n",
    "    droped = []\n",
    "    words = []\n",
    "    rsqu = []\n",
    "    pval = []\n",
    "    sigmoslope = []\n",
    "    IRTslope = []\n",
    "    regslope = []\n",
    "    sigmoint = []\n",
    "    IRTint = []\n",
    "    regint = []\n",
    "\n",
    "    with PdfPages('IRTplots.pdf') as pdf:\n",
    "        min = np.min(dat.Theta)\n",
    "        max = np.max(dat.Theta)\n",
    "\n",
    "        for word, wData in dat.groupby('Question'):\n",
    "\n",
    "            if word not in kept:\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                translation = translate(word)\n",
    "                translation = '\"' + translation + '\"; '\n",
    "            except:\n",
    "                translation = \"\"\n",
    "\n",
    "            fig, (ax1, ax2) = plt.subplots(1,2, figsize=(22,8.27))\n",
    "\n",
    "            # IRT fit\n",
    "            sns.scatterplot(x=wData.Theta, y=[x/8 for x in wData.Answer], ax=ax1)\n",
    "            t = np.arange(min, max, 0.01)\n",
    "            ax1.plot(t, [1/(1+np.exp(-wData.a.unique()[0]*(x-wData.b.unique()[0]))) for x in t],\n",
    "                    color=sns.color_palette()[1])\n",
    "            \n",
    "            # Logit reg\n",
    "            model = sm.Logit(endog=wData.DichoAnswers, exog=sm.add_constant(wData.EdLevelId))\n",
    "            results = model.fit()\n",
    "            if results.llr_pvalue < .001:\n",
    "                signif = \" (***)\"\n",
    "            elif results.llr_pvalue < .01:\n",
    "                signif = \" (**)\"\n",
    "            elif results.llr_pvalue < .05:\n",
    "                signif = \" (*)\"\n",
    "            else:\n",
    "                signif = \"\"\n",
    "\n",
    "            tmp = wData.copy()\n",
    "            tmp[\"Answer\"] = [x/8 for x in tmp.Answer]\n",
    "            size = pd.DataFrame(tmp.groupby([\"EdLevelId\", \"Answer\"]).size())\n",
    "            size.rename(columns={0: \"Headcount\"}, inplace=True)\n",
    "            tmpSize = tmp.join(size, on=[\"EdLevelId\", \"Answer\"])\n",
    "            # tmpSize[\"Headcount\"] = [x*3 for x in tmpSize.Headcount]\n",
    "            sns.scatterplot(tmpSize, x=\"EdLevelId\", y=\"Answer\", size=\"Headcount\", sizes=(50,230), ax=ax2)\n",
    "\n",
    "            t = np.arange(0, 10, 0.01)\n",
    "            ax2.plot(t, [1/(1+np.exp(-results.params[0]-x*results.params[1])) for x in t],\n",
    "                            color=sns.color_palette()[2])\n",
    "\n",
    "            # cosmetics\n",
    "            fig.suptitle(f\"Word: {word} ({translation}{vData.loc[vData.Question == word].WordLevelName.unique()[0]}) -- n = {len(wData)}\", fontsize=20)\n",
    "            ax1.set(xlabel=\"IRT estimated latent ability\", ylabel=\"Knowledge rating\", \n",
    "                ylim=[-0.1,1.1])\n",
    "            ax2.set(xlabel=\"Reported education level\", ylabel=\"Knowledge rating\", \n",
    "                ylim=[-0.1,1.1])\n",
    "            ax2.set_xticks(list(range(10)), labels=edLevelOrder, rotation=45, ha='right')\n",
    "            ax2.text(9, 0, f\"Pseudo $R^2$ = {results.prsquared:.2f}\\np = {results.llr_pvalue:.2e}{signif}\", \n",
    "                            horizontalalignment='center', verticalalignment='center',\n",
    "                            bbox={'edgecolor':'black', 'facecolor':'none'}, size=16)\n",
    "            ax2.legend(title=\"Headcount\", loc=\"upper left\", fontsize=16, title_fontsize=16)\n",
    "            \n",
    "            for item in ([ax1.xaxis.label, ax1.yaxis.label] + ax1.get_xticklabels() + ax1.get_yticklabels() +\n",
    "                         [ax2.xaxis.label, ax2.yaxis.label] + ax2.get_xticklabels() + ax2.get_yticklabels()):\n",
    "                item.set_fontsize(16)\n",
    "\n",
    "            plt.tight_layout()\n",
    "            pdf.savefig()\n",
    "            plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3c513b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation between IRT discrimination and STD of knowledge rating\n",
    "model = rankOLS(curatedIRTitems.STD, curatedIRTitems.a)\n",
    "results = model.fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.regplot(curatedIRTitems, x=\"a\", y=\"STD\", \n",
    "                 line_kws={'color': sns.color_palette()[1]})\n",
    "ax.set(xlabel=\"STD knowledge rating (per question)\", ylabel=\"IRT estimated discrimination param\")\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0095fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation between IRT difficulty and mean knowledge rating\n",
    "model = rankOLS(curatedIRTitems.Answer, curatedIRTitems.b)\n",
    "results = model.fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.regplot(curatedIRTitems, y=\"Answer\", x=\"b\", \n",
    "                 line_kws={'color': sns.color_palette()[1]})\n",
    "ax.set(ylabel=\"Mean of knowledge rating (per question)\", xlabel=\"IRT estimated difficulty param\")\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16b54da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation between IRT difficulty and word grade\n",
    "model = rankOLS(curatedIRTitems.WordLevelId, curatedIRTitems.b)\n",
    "results = model.fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4adeaa0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation between IRT difficulty and word frequency\n",
    "tmp = curatedIRTitems.join(vocData, on=\"Question\")\n",
    "tmp['LogMathsFreq'] = [np.log10(x)+6 for x in tmp.mathsFrequency]\n",
    "model = rankOLS(tmp.LogMathsFreq, tmp.b)\n",
    "results = model.fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4051aa50",
   "metadata": {},
   "source": [
    "##### Fit sigmoids and perform logistic regression on top and compare approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ce8d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot individual sigmoids\n",
    "eval = False\n",
    "plotRawIRT = True\n",
    "\n",
    "if eval:\n",
    "    \n",
    "    dat = vData.join(IRTsubjects.set_index('SubID'), on='SubID').join(IRTitems.set_index('Question'), on='Question')\n",
    "    dat['DichoAnswers'] = [0 if x <= 3 else 1 for x in dat.Answer]\n",
    "\n",
    "    kept = list(IRTdata.columns)\n",
    "    droped = []\n",
    "    words = []\n",
    "    rsqu = []\n",
    "    pval = []\n",
    "    sigmoslope = []\n",
    "    IRTslope = []\n",
    "    regslope = []\n",
    "    sigmoint = []\n",
    "    IRTint = []\n",
    "    regint = []\n",
    "\n",
    "    with PdfPages('SingleWordKnowledgeIRT.pdf') as pdf:\n",
    "        min = np.min(dat.Theta)\n",
    "        max = np.max(dat.Theta)\n",
    "\n",
    "        for level, lData in tqdm(dat.groupby('WordLevelName')):\n",
    "\n",
    "            with PdfPages(f'SingleWordKnowledgeIRT_{level}.pdf') as pdflevel:\n",
    "            \n",
    "                levelPage = plt.figure(figsize=(11.69,8.27))\n",
    "                levelPage.clf()\n",
    "                levelPage.text(0.5,0.5,level, transform=levelPage.transFigure, size=24, ha=\"center\")\n",
    "                pdf.savefig()\n",
    "                plt.close()\n",
    "\n",
    "                for word, wData in lData.groupby('Question'):\n",
    "\n",
    "                    if word not in kept:\n",
    "                        continue\n",
    "                    \n",
    "                    if plotRawIRT:\n",
    "                        fig, (ax1, ax2, ax3) = plt.subplots(1,3, figsize=(33,8.27))\n",
    "                    else:\n",
    "                        fig, (ax1, ax3) = plt.subplots(1,2, figsize=(22,8.27))\n",
    "\n",
    "                    # plot data points\n",
    "                    sns.scatterplot(x=wData.Theta, y=[x/8 for x in wData.Answer], ax=ax1)\n",
    "                    if plotRawIRT:\n",
    "                        sns.scatterplot(x=wData.Theta, y=[x/8 for x in wData.Answer], ax=ax2)\n",
    "                    tmp = wData.copy()\n",
    "                    tmp[\"Answer\"] = [x/8 for x in tmp.Answer]\n",
    "                    size = pd.DataFrame(tmp.groupby([\"EdLevelId\", \"Answer\"]).size())\n",
    "                    size.rename(columns={0: \"Headcount\"}, inplace=True)\n",
    "                    tmpSize = tmp.join(size, on=[\"EdLevelId\", \"Answer\"])\n",
    "                    tmpSize[\"Headcount\"] = [x*1.5 for x in tmpSize.Headcount]\n",
    "                    sns.scatterplot(tmpSize, x=\"EdLevelId\", y=\"Answer\", size=\"Headcount\", ax=ax3)\n",
    "\n",
    "                    # fit logistic regression\n",
    "                    try:\n",
    "                        model = sm.Logit(endog=wData.DichoAnswers, exog=sm.add_constant(wData.EdLevelId))\n",
    "                        results = model.fit()\n",
    "                        colour = \"black\" if results.llr_pvalue <= .05 else \"red\"\n",
    "                    except:\n",
    "                        droped.append(word)\n",
    "                        continue\n",
    "\n",
    "                    # fit sigmoid\n",
    "                    try:\n",
    "                        p0 = [np.max(wData.Answer)/8, np.median(wData.Theta), 1, np.min(wData.Answer)/8]\n",
    "                        popt, pcov = curve_fit(sigmoid, wData.Theta, [x/8 for x in wData.Answer], p0, method='dogbox', maxfev=10000)\n",
    "                        sigmoslope.append(popt[2])\n",
    "                        sigmoint.append(popt[1])\n",
    "                    except:\n",
    "                        droped.append(word)\n",
    "                        continue\n",
    "\n",
    "                    # plot fitted sigmoid\n",
    "                    t = np.arange(min, max, 0.01)\n",
    "                    ax1.plot(t, [sigmoid(x, *popt) for x in t],\n",
    "                            color=sns.color_pregalette()[1])\n",
    "\n",
    "                    # plot fitted IRT\n",
    "                    if plotRawIRT:\n",
    "                        t = np.arange(min, max, 0.01)\n",
    "                        ax2.plot(t, [1/(1+np.exp(-wData.a.unique()[0]*(x-wData.b.unique()[0]))) for x in t],\n",
    "                                color=sns.color_palette()[1])\n",
    "\n",
    "                    # plot fitted sigmoid\n",
    "                    t = np.arange(0, 10, 0.01)\n",
    "                    ax3.plot(t, [1/(1+np.exp(-results.params[0]-x*results.params[1])) for x in t],\n",
    "                            color=sns.color_palette()[2])\n",
    "\n",
    "                    # estimate slopes\n",
    "                    irtSlope = wData.a.unique()[0]\n",
    "                    logitSlope = results.params[1]\n",
    "                    \n",
    "                    # cosmetics\n",
    "                    fig.suptitle(f\"Word: {word} ({vData.loc[vData.Question == word].WordLevelName.unique()[0]}) -- N = {len(wData)}\")\n",
    "                    ax1.set(title=\"Sigmoid fit\", xlabel=\"IRT estimated latent ability\", ylabel=\"Knowledge rating\", \n",
    "                        ylim=[-0.1,1.1])\n",
    "                    ax3.set(title=\"Logistic regression\", xlabel=\"Reported education level\", ylabel=\"Knowledge rating\", \n",
    "                        ylim=[-0.1,1.1])\n",
    "                    ax3.set_xticks(list(range(10)), labels=edLevelOrder, rotation=45, ha='right')\n",
    "                    ax1.text(1, 0.5, f\"Fit discrimination param = {popt[2]:.2f}\\nFit difficulty param = {popt[1]:.2f}\",\n",
    "                            horizontalalignment='center', verticalalignment='center', \n",
    "                            color='black', bbox={'edgecolor':'black', 'facecolor':'none'})\n",
    "                    ax3.text(8.5, 0.5, f\"Pseudo $R^2$ = {results.prsquared:.2f}\\np = {results.llr_pvalue:.2e}\\nLogit discrimination param = {logitSlope:.2f}\\nLogit difficulty param = {-results.params[0]/results.params[1]:.2f}\", \n",
    "                            horizontalalignment='center', verticalalignment='center', \n",
    "                            color=colour, bbox={'edgecolor':'black', 'facecolor':'none'})\n",
    "                    if plotRawIRT:\n",
    "                        ax2.set(title=\"IRT fit\", xlabel=\"IRT estimated latent ability\", ylabel=\"Knowledge rating\", \n",
    "                            ylim=[-0.1,1.1])\n",
    "                        ax2.text(1, 0.5, f\"IRT discrimination param = {irtSlope:.2f}\\nIRT difficulty param = {wData.b.unique()[0]:.2f}\",\n",
    "                            horizontalalignment='center', verticalalignment='center', \n",
    "                            color='black', bbox={'edgecolor':'black', 'facecolor':'none'})\n",
    "\n",
    "                    \n",
    "                    if 'mathbb' in word:\n",
    "                        name = word.split('mathbb')[1][1:-2]\n",
    "                    elif word == '$\\\\pi$':\n",
    "                        name = 'pi'\n",
    "                    else:\n",
    "                        name = word\n",
    "\n",
    "                    plt.tight_layout()\n",
    "                    pdf.savefig()\n",
    "                    pdflevel.savefig()\n",
    "                    with PdfPages(f'./vocAnalyses/wordIRTplots/{name}.pdf') as localpdf:\n",
    "                        localpdf.savefig()\n",
    "                    plt.savefig(f'./vocAnalyses/wordIRTplots/{name}.png')\n",
    "                    plt.clf()\n",
    "\n",
    "                    words.append(word)\n",
    "                    rsqu.append(results.prsquared)\n",
    "                    pval.append(results.llr_pvalue)\n",
    "                    IRTslope.append(irtSlope)\n",
    "                    regslope.append(logitSlope)\n",
    "                    IRTint.append(wData.b.unique()[0])\n",
    "                    regint.append(-results.params[0]/results.params[1])\n",
    "\n",
    "\n",
    "    IRTLogit = pd.DataFrame({\"Word\": words, \"PseudoRSquared\": rsqu, \"LLRPval\": pval, \"SigmoidFitDiscrimination\": sigmoslope, \"SigmoidFitDifficulty\": sigmoint, \n",
    "                             \"IRTDiscrimination\": IRTslope, \"RegressionDiscrimination\": regslope, \"IRTDifficulty\": IRTint, \"RegressionDifficulty\": regint})\n",
    "    IRTLogit.to_csv('IRTLogit.csv', encoding='utf-8', index=False)\n",
    "\n",
    "else:\n",
    "\n",
    "    IRTLogit = pd.read_csv('IRTLogit.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a71adac",
   "metadata": {},
   "outputs": [],
   "source": [
    "IRTLogitSignif = IRTLogit[IRTLogit.LLRPval <= .05].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91190cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(IRTLogitSignif, x=\"PseudoRSquared\", binwidth=.01)\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc261b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation between IRT and logistic regression discrimination parameters\n",
    "model = ols(\"IRTDiscrimination ~ RegressionDiscrimination\", data=IRTLogitSignif)\n",
    "results = model.fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20475ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.regplot(IRTLogitSignif, x=\"RegressionDiscrimination\", y=\"IRTDiscrimination\", \n",
    "                 line_kws={'color': sns.color_palette()[1]})\n",
    "ax.set(xlabel=\"Logistic regression estimated discrimination param\", \n",
    "       ylabel=\"IRT estimated discrimination param\")\n",
    "ax.text(-10, 125, f\"$R^2$ = {results.rsquared:.2f}\\nN = {len(IRTLogitSignif)}\\np = {results.f_pvalue:.2e}\", \n",
    "        horizontalalignment='center', verticalalignment='center', bbox={'edgecolor':'black', 'facecolor':'none'})\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70222a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation between IRT and logistic regression discrimination parameters, restricted to cases where IRT discrimination parameters is <= 10 (not outrageous...)\n",
    "model = ols(\"IRTDiscrimination ~ RegressionDiscrimination\", data=IRTLogitSignif[IRTLogitSignif.IRTDiscrimination <= 10])\n",
    "results = model.fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375626bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.regplot(IRTLogitSignif[IRTLogitSignif.IRTDiscrimination <= 10], x=\"RegressionDiscrimination\", y=\"IRTDiscrimination\", \n",
    "                 line_kws={'color': sns.color_palette()[1]})\n",
    "ax.set(xlabel=\"Logistic regression estimated discrimination param\", \n",
    "       ylabel=\"IRT estimated discrimination param\", xlim=[0,2.2], ylim=[0,8])\n",
    "ax.text(1.75, 7, f\"$R^2$ = {results.rsquared:.2f}\\nN = {len(IRTLogitSignif[IRTLogitSignif.IRTDiscrimination <= 10])}\\np = {results.f_pvalue:.2e}\", \n",
    "        horizontalalignment='center', verticalalignment='center', bbox={'edgecolor':'black', 'facecolor':'none'})\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "debec43f",
   "metadata": {},
   "source": [
    "#### Graded Response Model (using R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c97479",
   "metadata": {},
   "outputs": [],
   "source": [
    "runGRM = False\n",
    "\n",
    "GRMdata = vData.groupby([\"SubID\", \"Question\"]).min().reset_index().pivot(index=\"SubID\", columns=\"Question\", values=\"Answer\")\n",
    "\n",
    "if runGRM:\n",
    "\n",
    "    GRMdata.to_csv(\"vocAnalyses/GRMData.csv\")\n",
    "\n",
    "    rscript = os.path.normpath(os.path.join(os.getcwd(), 'GRM.R'))\n",
    "    ret = subprocess.run([which('Rscript'), rscript])\n",
    "    assert(ret.returncode == 0)\n",
    "\n",
    "    GRMitems = pd.read_csv(\"GRMitems.csv\", encoding='utf-8')\n",
    "    GRMsubjects = pd.read_csv(\"GRMsubjects.csv\", encoding='utf-8')\n",
    "\n",
    "    GRMsubjects['SubID'] = GRMdata.index\n",
    "    GRMsubjects.rename(columns={'F1':'Theta'}, inplace=True)\n",
    "    GRMsubjects.drop(columns='Unnamed: 0', inplace=True)\n",
    "\n",
    "    GRMitems.drop(columns=['means', 'F1'], inplace=True)\n",
    "    GRMitems.rename(columns={'Unnamed: 0': 'Question'}, inplace=True)\n",
    "    GRMitems.set_index('Question', inplace=True)\n",
    "    GRMitems.rename(index={'X..mathbb.C..': '$\\\\mathbb{C}$', 'X..mathbb.N..': '$\\\\mathbb{N}$', 'X..mathbb.Q..': '$\\\\mathbb{Q}$', 'X..mathbb.R..': '$\\\\mathbb{R}$', 'X..mathbb.Z..': '$\\\\mathbb{Z}$', 'X..pi.': '$\\\\pi$'}, inplace=True)\n",
    "    GRMitems.rename(columns={x: x.split('.')[-1] for x in GRMitems.columns}, inplace=True)\n",
    "\n",
    "    for word, wordData in vData.groupby('Question'):\n",
    "        levels = np.sort(wordData.Answer.unique())[1:]\n",
    "        bs = list(GRMitems.loc[word].dropna())[1:]\n",
    "        for i in range(1,9):\n",
    "            GRMitems.at[word, f'b{int(i)}'] = np.nan\n",
    "        for level, b in zip(levels, bs):\n",
    "            GRMitems.at[word, f'b{int(level)}'] = b\n",
    "\n",
    "    GRMitems.to_csv('GRMitems.csv', encoding='utf-8')\n",
    "    GRMsubjects.to_csv('GRMsubjects.csv', encoding='utf-8')\n",
    "\n",
    "else:\n",
    "    \n",
    "    GRMitems = pd.read_csv(\"GRMitems.csv\", encoding='utf-8')\n",
    "    GRMsubjects = pd.read_csv(\"GRMsubjects.csv\", encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a853b4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check rank correlation between IRT estimated theta and participants' reported education level\n",
    "GRMSubLevel = subData.join(GRMsubjects.set_index('SubID'), on='SubID')\n",
    "model = rankOLS(GRMSubLevel.Theta, [GRMSubLevel.EdLevelId, GRMSubLevel.SelfAssessment])\n",
    "result = model.fit()\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342c0f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.histplot(GRMsubjects, x='Theta', binwidth=.1)\n",
    "ax.vlines(x=np.mean(GRMsubjects.Theta), ymin=0, ymax=60, colors=sns.color_palette()[1])\n",
    "ax.set(xlabel=\"Theta\")\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f367a15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.histplot(GRMitems, x='a', binwidth=.1)\n",
    "ax.set(xlabel=\"Slope\")\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ba6cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "GRMitems.sort_values(by='a', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e945d609",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot individual sigmoids\n",
    "eval = False\n",
    "\n",
    "if eval:\n",
    "    \n",
    "    with PdfPages('SingleWordKnowledgeGRM.pdf') as pdf:\n",
    "        min = np.min(GRMSubLevel.Theta)\n",
    "        max = np.max(GRMSubLevel.Theta)\n",
    "\n",
    "        for word, wData in tqdm(GRMSubLevel.groupby('Question')):\n",
    "            \n",
    "            # plot data points\n",
    "            ax = sns.lineplot(GRMSubLevel, x='Theta', y='Answer')\n",
    "            \n",
    "            # fit sigmoid\n",
    "            p0 = [np.max(wData.Answer), np.median(wData.EdLevelId), 1, np.min(wData.Answer)]\n",
    "            popt, pcov = curve_fit(sigmoid, wData.EdLevelId, wData.Answer, p0, method='dogbox', maxfev=10000)\n",
    "            \n",
    "            # compute R^2 for the fit\n",
    "            residuals = wData.Answer - sigmoid(wData.EdLevelId, *popt)\n",
    "            ss_res = np.sum(residuals**2)\n",
    "            ss_tot = np.sum((wData.Answer-np.mean(wData.Answer))**2)\n",
    "            r_squared = 1 - (ss_res / ss_tot)\n",
    "            colour = sns.color_palette[3] if r_squared >= 0.7 else 'black'\n",
    "            \n",
    "            # plot fitted sigmoid\n",
    "            t = np.arange(min, max, 0.01)\n",
    "            plt.plot(t, [sigmoid(x, *popt) for x in t], label=\"fitted sigmoid\", \n",
    "                     color=sns.color_palette()[1])\n",
    "\n",
    "            # estimate slopes\n",
    "            estSlope = GRMitems[GRMitems.Question == word].a.values[0]\n",
    "            actSlope = popt[0]*popt[2]/4\n",
    "            colour = \"none\" if np.abs(estSlope-actSlope)/estSlope <= .05 else \"red\"\n",
    "            \n",
    "            # cosmetics\n",
    "            ax.set(title=f\"Word: {word} ({vData.loc[vData.Question == word].WordLevelName.unique()[0]})\", \n",
    "                   xlabel=\"Estimated $\\\\theta$\", ylabel=\"Knowledge rating (from 0 to 8)\", \n",
    "                   ylim=[-0.1,8.1])\n",
    "            ax.text(0.5, 7.5, f\"N = {len(wData)}\", horizontalalignment='center')\n",
    "            ax.text(8.5, 0.5, f\"Fit $R^2$ = {r_squared:.2f}\\nIRT estimated slope = {estSlope:.2f}\\nActual slope = {actSlope:.2f}\",\n",
    "                    horizontalalignment='center', verticalalignment='center', \n",
    "                    color=colour, bbox={'edgecolor':'black', 'facecolor':'none'})\n",
    "            \n",
    "            plt.legend()\n",
    "            pdf.savefig()\n",
    "            plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29c4925",
   "metadata": {},
   "source": [
    "#### Comparison of the above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585f222d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation test\n",
    "model = sm.OLS(endog=GRMsubjects.Theta, exog=sm.add_constant(IRTsubjects.Theta))\n",
    "results = model.fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2227b18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.regplot(x=IRTsubjects.Theta, y=GRMsubjects.Theta, \n",
    "                 line_kws={'color': sns.color_palette()[1]})\n",
    "ax.set(xlabel=\"Theta for dichotomised IRT\", \n",
    "       ylabel=\"Theta for GRM\")\n",
    "ax.text(-2.5, 2.5, f\"$R^2$ = {results.rsquared:.2f}\\nN = {len(IRTsubjects)}\\np = {results.f_pvalue:.2e}\", \n",
    "        horizontalalignment='center', verticalalignment='center', bbox={'edgecolor':'black', 'facecolor':'none'})\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0769003",
   "metadata": {},
   "source": [
    "## Word similarity analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104330f3",
   "metadata": {},
   "source": [
    "Questions:\n",
    "- Do subjects agree on the similarities of math words? (split-half consistency)\n",
    "- Is GloVe a good model of those similarities?\n",
    "- Do similarities change with education (get refined?? get more similar to Glove??)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a54b850",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data\n",
    "pData = df.loc[df.Trial == 'SimilarityJudgement'].copy()\n",
    "pData.drop(['Trial', 'RT', 'WordLevelId', 'WordLevelName'], \n",
    "           axis=1, inplace=True)\n",
    "pData.rename({'Similarity': 'GloVeSimilarity', 'SubLevel': 'StimLevelCategory'}, axis=1, inplace=True)\n",
    "pData['Training'] = [not i for i in pData.Training] # fix this unintuitive issue\n",
    "pData['Answer'] = pData.Answer.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf69845e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove training data\n",
    "pMathsData = pData.loc[~pData.Training].copy()\n",
    "# remove unanswered questions\n",
    "pMathsDataFiltered = pMathsData.dropna(subset=[\"Answer\"]).copy()\n",
    "# average over participants for each question\n",
    "pMathsDataAgg = pMathsDataFiltered.groupby(\"Question\").mean(numeric_only=True).join(stimData[['word1', 'word2']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f827776f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pMathsDataAgg['MeanKnowledge'] = [np.mean([vData[vData.Question == x.word1].Answer.mean(),vData[vData.Question == x.word2].Answer.mean()]) for x in pMathsDataAgg.itertuples()]\n",
    "pMathsDataAgg['MeanFreq'] = [np.mean([vocData.loc[x.word1].mathsFrequency, vocData.loc[x.word2].mathsFrequency]) for x in pMathsDataAgg.itertuples()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caaac08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pData"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78b0d95",
   "metadata": {},
   "source": [
    "### Sanity checks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2da3e22",
   "metadata": {},
   "source": [
    "#### Training questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd4ebac",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingData = pData.loc[pData.Training]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ceb9119",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.boxplot(trainingData, x=\"Question\", y=\"Answer\")\n",
    "ax.tick_params(axis='x', rotation=45)\n",
    "ax.set(xlabel=\"Training pair\", ylabel=\"Distribution of estimated proximity\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2baf90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.displot(trainingData, x=\"Answer\", col=\"Question\", kde=True,\n",
    "                col_wrap=4, facet_kws={'sharey':False})\n",
    "g.set_titles(col_template='Pair: \"{col_name}\"')\n",
    "g.set(xlabel=\"Estimated proximity\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2582a707",
   "metadata": {},
   "source": [
    "#### Number of presentation of each pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be0ec32",
   "metadata": {},
   "outputs": [],
   "source": [
    "numPres = pMathsDataFiltered.groupby(\"Question\").count()\n",
    "numPresOrder = pMathsDataFiltered.groupby([\"Question\", \"PresentationOrder\"]).count()\n",
    "numPresOrder['Order'] = numPresOrder.index.get_level_values('PresentationOrder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8c38f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.boxplot(numPres, x='SubID', showmeans=True)\n",
    "ax.set(xlabel=\"Number of presentations of each pair\")\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5efb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.histplot(numPres, x='SubID')\n",
    "ax.set(xlabel=\"Number of presentation of each pair\")\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b6a20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.boxplot(numPresOrder, x='SubID', y='Order', showmeans=True)\n",
    "ax.set(xlabel=\"Number of presentations of each pair\")\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608f11fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.histplot(numPresOrder, x='SubID', hue='Order')\n",
    "ax.set(xlabel=\"Number of presentation of each pair\")\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2bcc17",
   "metadata": {},
   "source": [
    "#### Effect of order of presentation of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d62794b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = pMathsData.groupby(['Question', 'PresentationOrder'], as_index=False).mean(numeric_only=True)\n",
    "orderPresentationData = tmp.pivot(index='Question', columns='PresentationOrder', values='Answer')\n",
    "orderPresentationData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2897d25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation test\n",
    "model = ols(\"word2_word1 ~ word1_word2\", data=orderPresentationData)\n",
    "results = model.fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54972ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.regplot(orderPresentationData, x=\"word1_word2\", y=\"word2_word1\", \n",
    "                 line_kws={'color': sns.color_palette()[1]})\n",
    "ax.set(xlabel=\"Mean human judged similarity per pair (word1-word2)\", \n",
    "       ylabel=\"Mean human judged similarity per pair (word2-word1)\")\n",
    "ax.text(0.5, 4.8, f\"$R^2$ = {results.rsquared:.2f}\\nN = {len(orderPresentationData)}\\np = {results.f_pvalue:.2e}\", \n",
    "        horizontalalignment='center', verticalalignment='center', bbox={'edgecolor':'black', 'facecolor':'none'})\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d8d593",
   "metadata": {},
   "outputs": [],
   "source": [
    "# two-sample Kolmogorov–Smirnov test\n",
    "eval = False\n",
    "\n",
    "allPbPairs = []\n",
    "\n",
    "if eval:\n",
    "\n",
    "    with PdfPages('PresentationOrderEffects.pdf') as pdf:\n",
    "\n",
    "        for i, (pair, pairData) in enumerate(pMathsData.groupby(\"Question\")):\n",
    "\n",
    "            # setup data\n",
    "            words = pair.split('_')\n",
    "            directOrder = pairData.loc[pairData.PresentationOrder == \"word1_word2\"].Answer\n",
    "            reverseOrder = pairData.loc[pairData.PresentationOrder == \"word2_word1\"].Answer\n",
    "           \n",
    "            # descriptive stats\n",
    "            ld = len(directOrder)\n",
    "            lr = len(reverseOrder)\n",
    "            md = np.mean(directOrder)\n",
    "            mr = np.mean(reverseOrder)\n",
    "            sd = np.std(directOrder)\n",
    "            sr = np.std(reverseOrder)\n",
    "            \n",
    "            # plot distributions\n",
    "            ax = sns.kdeplot(pairData, x=\"Answer\", hue=\"PresentationOrder\", cut=0,\n",
    "                            hue_order=[\"word1_word2\", \"word2_word1\"])\n",
    "            \n",
    "            # plot mean and std\n",
    "            if len(ax.lines) < 2:\n",
    "                sns.histplot(pairData, x=\"Answer\", hue=\"PresentationOrder\", ax=ax,\n",
    "                             hue_order=[\"word1_word2\", \"word2_word1\"])\n",
    "            else:\n",
    "                directLine = ax.lines[1]\n",
    "                xDirect, yDirect = directLine.get_xdata(), directLine.get_ydata()\n",
    "                reverseLine = ax.lines[0]\n",
    "                xReverse, yReverse = reverseLine.get_xdata(), reverseLine.get_ydata()\n",
    "                ax.vlines(md, 0, np.interp(md, xDirect, yDirect), color=sns.color_palette()[0], ls=':')\n",
    "                ax.vlines(mr, 0, np.interp(mr, xReverse, yReverse), color=sns.color_palette()[1], ls=':')\n",
    "                ax.fill_between(xDirect, 0, yDirect, where=(md-sd <= xDirect) & (xDirect <= md+sd), \n",
    "                                interpolate=True, facecolor=sns.color_palette()[0], alpha=0.2)\n",
    "                ax.fill_between(xReverse, 0, yReverse, where=(mr-sr <= xReverse) & (xReverse <= mr+sr), \n",
    "                                interpolate=True, facecolor=sns.color_palette()[1], alpha=0.2)\n",
    "\n",
    "            # perform KS test\n",
    "            res = stats.kstest(directOrder, reverseOrder)\n",
    "            \n",
    "            # add KS info to plot\n",
    "            colour = 'red' if res.pvalue < .01 else 'none'\n",
    "            ax.text(0.1, 0.1, f\"KS stat = {res.statistic:.2f}\\np = {res.statistic:.2e}\",\n",
    "                    transform=ax.transAxes,\n",
    "                    horizontalalignment='center', verticalalignment='center', bbox={'edgecolor':'black', 'facecolor': colour})\n",
    "\n",
    "            # cosmetics\n",
    "            L = ax.get_legend()\n",
    "            ax.legend(title=\"Presentation order\", handles=L.legend_handles,\n",
    "                      labels=[', '.join(words)+f' (N = {ld})', ', '.join(words[::-1])+f' (N = {lr})'])\n",
    "            ax.set(title=f\"Pair: {'-'.join(words)}\", xlabel=\"Estimated similarity\", xlim=[-.1, 5.1])\n",
    "\n",
    "            # save fig\n",
    "            plt.tight_layout()\n",
    "            pdf.savefig()\n",
    "            plt.clf()\n",
    "\n",
    "            # print useful info\n",
    "            if ld/lr < .9 and lr/ld < .9:\n",
    "                allPbPairs.append('Bad distribution: '+pair)\n",
    "            if res.pvalue < .01:\n",
    "                allPbPairs.append(f'Cannot reject alternative hypothesis: {pair} (p = {res.pvalue:.2e})')\n",
    "\n",
    "\n",
    "    print('Proportion of problematic pairs: ', 100*len(allPbPairs)/len(pMathsData.groupby(\"Question\").mean(numeric_only=True)))\n",
    "    print('\\n'.join(allPbPairs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176daf6d",
   "metadata": {},
   "source": [
    "### Overall analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aff9781",
   "metadata": {},
   "source": [
    "#### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca329370",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = pd.read_csv('../Embeddings/French/words_vec_50_maths.csv', index_col=\"word\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7830c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairLevelToCat(l):\n",
    "    if l == 0:\n",
    "        return 0\n",
    "    elif l <= 2:\n",
    "        return 2\n",
    "    elif l <= 4:\n",
    "        return 4\n",
    "    elif l <= 5:\n",
    "        return 5\n",
    "    else:\n",
    "        return 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05f4000",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add euclidean distance\n",
    "pMathsDataAgg['EuclideanDistance'] = [np.linalg.norm(np.array(vectors.loc[t.word1])-np.array(vectors.loc[t.word2])) for t in pMathsDataAgg.itertuples()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004d9cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add categorical levels of predicted similarities\n",
    "pMathsDataAgg['CategoricalSim'] = ['']*len(pMathsDataAgg)\n",
    "for l, levelData in pMathsDataAgg.groupby(\"PairLevel\"):\n",
    "    level = pairLevelToCat(l)\n",
    "    df = pd.read_csv(f\"../Data/FrenchPairs/selectedPairs_{level}.csv\", index_col=\"PairID\")\n",
    "    for t in levelData.itertuples():\n",
    "        pMathsDataAgg.at[t.Index, 'CategoricalSim'] = df.loc[t.Index].SimCategory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21fbaf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "catSimOrder = [\"Furthest\", \"Orthogonal\", \"Average\", \"Closest\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3c5f47",
   "metadata": {},
   "source": [
    "#### Compute noise ceiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a4354b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossVal(data, other, stimVar, respVar, groups):\n",
    "    a = []\n",
    "    p = []\n",
    "    r2 = []\n",
    "    \n",
    "    for fold, foldData in data.groupby(groups):\n",
    "        \n",
    "        otherData = other[other[groups] != fold]\n",
    "        otherData = otherData.groupby(stimVar).mean(numeric_only=True)\n",
    "        \n",
    "        allData = otherData.join(foldData.set_index(stimVar), how='inner', rsuffix='fold')\n",
    "        allData.dropna(subset=[respVar, respVar+'fold'], how='any', inplace=True)\n",
    "        \n",
    "        if len(allData[respVar].unique()) >= 2 and len(allData[respVar+'fold'].unique()) >= 2:\n",
    "        \n",
    "            p.append(len(foldData)-len(allData))\n",
    "            \n",
    "            model = rankOLS(allData[respVar+'fold'], allData[respVar], missing='drop')\n",
    "            result = model.fit()\n",
    "            r2.append(result.rsquared)\n",
    "            a.append(result.params[1])\n",
    "\n",
    "    return np.mean(r2), a, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96751e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "noiseCeiling = {}\n",
    "allA = []\n",
    "allP = []\n",
    "lab = []\n",
    "\n",
    "noiseCeiling['Global'], a, p = crossVal(pMathsDataFiltered, pMathsDataFiltered, 'Question', 'Answer', 'SubID')\n",
    "\n",
    "allA += a\n",
    "allP += p\n",
    "lab += [\"Global\"] * len(a)\n",
    "\n",
    "for (level, levelId), levelData in pMathsDataFiltered.groupby(['EdLevel', 'EdLevelId']):\n",
    "    cval, a, p = crossVal(levelData, pMathsDataFiltered, 'Question', 'Answer', 'SubID')\n",
    "    \n",
    "    noiseCeiling[level] = cval\n",
    "    noiseCeiling[levelId] = cval\n",
    "    allA += a\n",
    "    allP += p\n",
    "    lab += [level] * len(a)\n",
    "    \n",
    "noiseData = pd.DataFrame({\"Level\": lab, \"Slopes\": allA, \"N\": allP})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62d3acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(noiseCeiling['Global'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eedf29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "allA = []\n",
    "noiseCeilingWordLevel = {}\n",
    "allP = []\n",
    "lab = []\n",
    "\n",
    "for (levelId, levelData), level in zip(pMathsDataFiltered.groupby('PairLevel'), wordLevelOrder):\n",
    "\n",
    "    cval, a, p = crossVal(levelData, pMathsDataFiltered, 'Question', 'Answer', 'SubID')\n",
    "\n",
    "    noiseCeilingWordLevel[level] = cval\n",
    "    noiseCeilingWordLevel[levelId] = cval\n",
    "    allA += a\n",
    "    allP += p\n",
    "    lab += [level] * len(a)\n",
    "    \n",
    "noiseDataWordLevel = pd.DataFrame({\"Level\": lab, \"Slopes\": allA, \"N\": allP})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89a08fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.displot(noiseData, x=\"Slopes\", kind='kde', col=\"Level\", cut=0,\n",
    "                col_wrap=4, col_order=[\"Global\"]+edLevelOrder, facet_kws={'sharey':False})\n",
    "g.refline(x=0)\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0559919f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each fold, number of trials that were unique to the fold (pairs presented only to the left-over participant)\n",
    "ax = sns.boxplot(noiseData, x=\"N\", y=\"Level\", order=[\"Global\"]+edLevelOrder)\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d11f80",
   "metadata": {},
   "source": [
    "##### Noise ceiling depending on order of presentation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9abfa4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdirect = []\n",
    "rreverse = []\n",
    "\n",
    "for sub in pMathsDataFiltered.SubID.unique():\n",
    "    this = pMathsDataFiltered[pMathsDataFiltered.SubID == sub]\n",
    "    other = pMathsDataFiltered[~(pMathsDataFiltered.SubID == sub)].groupby(['Question', 'PresentationOrder']).mean()\n",
    "    other['ReverseOrder'] = ['word2_word1' if x == 'word1_word2' else 'word1_word2' for _, x in other.index]\n",
    "    other.set_index('ReverseOrder', append=True, inplace=True)\n",
    "\n",
    "    # same order\n",
    "    sameOrder = this.join(other.droplevel('ReverseOrder'), on=['Question', 'PresentationOrder'], rsuffix=\"_other\")\n",
    "    sameOrder.dropna(subset=['Answer', 'Answer_other'], how='any', inplace=True)\n",
    "    res = stats.pearsonr(sameOrder.Answer, sameOrder.Answer_other)\n",
    "    rdirect.append(res.statistic)\n",
    "\n",
    "    # reverse order\n",
    "    reverseOrder = this.join(other.droplevel('PresentationOrder'), on=['Question', 'PresentationOrder'], rsuffix=\"_other\")\n",
    "    reverseOrder.dropna(subset=['Answer', 'Answer_other'], how='any', inplace=True)\n",
    "    res = stats.pearsonr(reverseOrder.Answer, reverseOrder.Answer_other)\n",
    "    rreverse.append(res.statistic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6feecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "crossValOrderPres = pd.DataFrame({'Same order': rdirect, 'Opposite order': rreverse}, index=pd.Index(name='SubID', data=pMathsDataFiltered.SubID.unique()))\n",
    "crossValOrderPres.columns.name = \"Order\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df311f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(pd.DataFrame(crossValOrderPres.stack()).rename(columns={0: 'Correlation'}).reset_index(), x='Order', y='Correlation')\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b7fc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.ttest_ind(crossValOrderPres['Same order'], crossValOrderPres['Opposite order'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9497fcd8",
   "metadata": {},
   "source": [
    "#### Correlation between rated similarity and our four categorical levels of predicted similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb08489",
   "metadata": {},
   "outputs": [],
   "source": [
    "pMathsDataAgg.groupby(\"CategoricalSim\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8b1396",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kruskal-Wallis\n",
    "tmp = pMathsDataAgg.reset_index().pivot(index='Question', columns='CategoricalSim', values='Answer')\n",
    "stats.kruskal(tmp.Average, tmp.Closest, tmp.Furthest, tmp.Orthogonal, nan_policy='omit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93e73a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dunn\n",
    "posthoc_dunn(pMathsDataAgg, val_col=\"Answer\", group_col=\"CategoricalSim\", p_adjust=\"bonferroni\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c067e73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.violinplot(pMathsDataAgg, x=\"CategoricalSim\", y=\"Answer\", \n",
    "                    order=catSimOrder)\n",
    "ax.set(xlabel=\"Categorical levels of GloVe predicted similarities (cosine)\", ylabel=\"Distribution of human estimated similarity\")\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee2511c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.boxplot(pMathsDataAgg, x=\"CategoricalSim\", y=\"Answer\", \n",
    "                 order=catSimOrder)\n",
    "ax.set(xlabel=\"Categorical levels of GloVe predicted similarities (cosine)\", ylabel=\"Distribution of human estimated similarity\")\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff3a858",
   "metadata": {},
   "source": [
    "#### Correlation between rated similarity and a continuous measure (cosine angle or Euclidean distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a677484c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantileCut(df, cols, q=100):\n",
    "    \n",
    "    def oneshot(df, col, q):\n",
    "        quantiles = pd.DataFrame(pd.qcut(df[col], q=q))\n",
    "        tmp = df.join(quantiles, rsuffix=\"_bins\")\n",
    "        means = tmp.groupby(col+'_bins').mean()\n",
    "        means = pd.DataFrame(means[col])\n",
    "        dff = tmp.join(means, on=col+'_bins', rsuffix='Bins')\n",
    "        dff.drop(columns=[col+'_bins'], inplace=True)\n",
    "        return dff\n",
    "    \n",
    "    if len(np.shape(cols)) == 0:\n",
    "        cols = np.reshape(cols, (len(cols)))\n",
    "\n",
    "    for col in cols:\n",
    "        df = oneshot(df, col, q)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268de517",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    assert not pMathsDataAgg_cop is None\n",
    "except:\n",
    "    pMathsDataAgg_cop = pMathsDataAgg.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45162a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pMathsDataAgg = quantileCut(pMathsDataAgg, ['EuclideanDistance', 'GloVeSimilarity', 'Answer'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4ce094",
   "metadata": {},
   "source": [
    "##### Cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119fc060",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spearman's rank correlation analysis\n",
    "res = stats.spearmanr(pMathsDataAgg.AnswerBins, pMathsDataAgg.GloVeSimilarityBins)\n",
    "display(Markdown(rf\"Spearman's $r_s$ coefficient: {res.statistic:.2f} (p = {res.pvalue:.2e})<br>$r_s^2$ = {res.statistic**2:.3f}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5cc5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = rankOLS(pMathsDataAgg.AnswerBins, pMathsDataAgg.GloVeSimilarityBins)\n",
    "results = model.fit()\n",
    "results.summary2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691c3b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# article fig\n",
    "g = sns.JointGrid(pMathsDataAgg, x=\"GloVeSimilarityBins\", y=\"AnswerBins\")\n",
    "g.plot_joint(sns.lineplot)\n",
    "g.plot_marginals(sns.histplot, kde=True)\n",
    "g.ax_joint.axvline(x=0, linestyle='--', color='.4')\n",
    "#g.set_axis_labels(\"GloVe similarity\", \"Human similarity\")\n",
    "g.set_axis_labels(\"\",\"\")\n",
    "# g.ax_joint.text(0.7, 0.5, f\"N = {len(pMathsDataAgg.Answer)}\\nSpearman's $r_s$ = {res.statistic:.2f}\\np < .001\", \n",
    "#                 horizontalalignment='center', verticalalignment='center', bbox={'edgecolor':'black', 'facecolor':'none'})\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(figWidth/1.2, figWidth*ratio)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858bd6fc",
   "metadata": {},
   "source": [
    "##### Cosine similarity on rank data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d739a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pMathsDataFiltered['RankAnswer'] = pMathsDataFiltered.groupby('SubID')['Answer'].rank('average')\n",
    "pMathsDataFiltered['RankAnswerNorm'] = pMathsDataFiltered.groupby('SubID')['RankAnswer'].transform(lambda x: x/x.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec5d97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pMathsDataRank = pMathsDataFiltered.groupby('Question').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53091b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pMathsDataRank = quantileCut(pMathsDataRank, ['GloVeSimilarity', 'RankAnswerNorm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400e99fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spearman's rank correlation analysis\n",
    "res = stats.spearmanr(pMathsDataRank.RankAnswerNormBins, pMathsDataRank.GloVeSimilarityBins)\n",
    "display(Markdown(rf\"Spearman's $r_s$ coefficient: {res.statistic:.2f} (p = {res.pvalue:.2e})<br>$r_s^2$ = {res.statistic**2:.3f}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436ecb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = rankOLS(pMathsDataRank.RankAnswerNormBins, pMathsDataRank.GloVeSimilarityBins)\n",
    "results = model.fit()\n",
    "results.summary2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78fa6966",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.JointGrid(pMathsDataRank, x=\"GloVeSimilarityBins\", y=\"RankAnswerNormBins\")\n",
    "g.plot_joint(sns.lineplot)\n",
    "g.plot_marginals(sns.histplot, kde=True)\n",
    "g.ax_joint.axvline(x=0, linestyle='--', color='.4')\n",
    "#g.set_axis_labels(\"GloVe similarity\", \"Human similarity\")\n",
    "g.set_axis_labels(\"\",\"\")\n",
    "# g.ax_joint.text(0.7, 0.5, f\"N = {len(pMathsDataAgg.Answer)}\\nSpearman's $r_s$ = {res.statistic:.2f}\\np < .001\", \n",
    "#                 horizontalalignment='center', verticalalignment='center', bbox={'edgecolor':'black', 'facecolor':'none'})\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(figWidth/1.2, figWidth*ratio)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba73a68",
   "metadata": {},
   "source": [
    "##### Cosine similarity for predicted similarities between 0 and 0.4 only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8d7238",
   "metadata": {},
   "outputs": [],
   "source": [
    "avgPred = pMathsDataAgg_cop[(pMathsDataAgg_cop.GloVeSimilarity <= 0.4) & (pMathsDataAgg_cop.GloVeSimilarity >= 0)]\n",
    "avgPred = quantileCut(avgPred, ['Answer', 'GloVeSimilarity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0890e91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = stats.spearmanr(avgPred.AnswerBins, avgPred.GloVeSimilarityBins)\n",
    "display(Markdown(rf\"Spearman's $r_s$ coefficient: {res.statistic:.2f} (p = {res.pvalue:.2e})<br>$r_s^2$ = {res.statistic**2:.3f}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e801c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = rankOLS(avgPred.AnswerBins, avgPred.GloVeSimilarityBins)\n",
    "results = model.fit()\n",
    "results.summary2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727918c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "bic = results.bic\n",
    "display(Markdown(rf\"BIC = {bic}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647218ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.JointGrid(avgPred, x=\"GloVeSimilarityBins\", y=\"AnswerBins\", height=11.7)\n",
    "g.plot_joint(sns.lineplot)\n",
    "g.plot_marginals(sns.histplot, kde=True)\n",
    "g.set_axis_labels(\"GloVe predicted similarity (cosine)\", \"Average human judged similarity by item\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406c2892",
   "metadata": {},
   "source": [
    "##### Cosine similarity for negative predicted similarities only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5c3cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "negPred = pMathsDataAgg_cop[pMathsDataAgg_cop.GloVeSimilarity <= 0]\n",
    "negPred = quantileCut(negPred, ['Answer', 'GloVeSimilarity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d9d264",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = stats.spearmanr(negPred.AnswerBins, negPred.GloVeSimilarityBins)\n",
    "display(Markdown(rf\"Spearman's $r_s$ coefficient: {res.statistic:.2f} (p = {res.pvalue:.2e})<br>$r_s^2$ = {res.statistic**2:.3f}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706b383e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = rankOLS(negPred.AnswerBins, negPred.GloVeSimilarityBins)\n",
    "results = model.fit()\n",
    "results.summary2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7685ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "bic = results.bic\n",
    "display(Markdown(rf\"BIC = {bic}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782ca198",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.JointGrid(negPred, x=\"GloVeSimilarityBins\", y=\"AnswerBins\", height=11.7)\n",
    "g.plot_joint(sns.lineplot)\n",
    "g.plot_marginals(sns.histplot, kde=True)\n",
    "g.set_axis_labels(\"GloVe predicted similarity (cosine)\", \"Average human judged similarity by item\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ae2046",
   "metadata": {},
   "source": [
    "##### Euclidean distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc8bca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spearman's rank correlation analysis\n",
    "res = stats.spearmanr(pMathsDataAgg.AnswerBins, pMathsDataAgg.EuclideanDistanceBins)\n",
    "display(Markdown(rf\"Spearman's $r_s$ coefficient: {res.statistic:.2f} (p = {res.pvalue:.2e})<br>$r_s^2$ = {res.statistic**2:.3f}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba24c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = rankOLS(pMathsDataAgg.AnswerBins, pMathsDataAgg.EuclideanDistanceBins)\n",
    "results = model.fit()\n",
    "results.summary2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9b062a",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.JointGrid(pMathsDataAgg, x=\"EuclideanDistanceBins\", y=\"AnswerBins\", height=11.7)\n",
    "g.plot_joint(sns.lineplot)\n",
    "g.plot_marginals(sns.histplot, kde=True)\n",
    "g.set_axis_labels(\"GloVe predicted distance (Euclidean)\", \"Average human judged similarity by item\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6cfaf2f",
   "metadata": {},
   "source": [
    "##### Embedding pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d265b261",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune(humanSim, embeddings):\n",
    "    \"\"\"\n",
    "    implementation of the pruning algorithm described in Manrique, N. F., Bao, W., Herbelot, A., & Hasson, U. (2023). Enhancing Interpretability using Human Similarity Judgements to Prune Word Embeddings (arXiv:2310.10262). arXiv. http://arxiv.org/abs/2310.10262\n",
    "\n",
    "    \"\"\"\n",
    "    words = list(embeddings.index)\n",
    "    embeddings = embeddings.to_numpy()\n",
    "    nwords, nfeatures = embeddings.shape\n",
    "\n",
    "    humanSim = humanSim.to_numpy()\n",
    "\n",
    "    # Compute baseline Spearman’s Rho\n",
    "    modelSim = 1-pairwise_distances(embeddings, embeddings, metric='cosine')\n",
    "    baseline = stats.spearmanr(humanSim.flatten(), modelSim.flatten(), nan_policy='omit').statistic\n",
    "\n",
    "    # Rank features\n",
    "    diff = []\n",
    "    for i in range(nfeatures):\n",
    "        partial = np.delete(embeddings, i, axis=1)\n",
    "        partialSim = 1-pairwise_distances(partial, partial, metric='cosine')\n",
    "        rho = stats.spearmanr(humanSim.flatten(), partialSim.flatten(), nan_policy='omit').statistic\n",
    "        diff.append(baseline-rho)\n",
    "    featuresImportance = np.argsort(diff)[::-1]\n",
    "\n",
    "    # Construct pruned embeddings\n",
    "    a = []\n",
    "    for i in range(nfeatures):\n",
    "        toRemove = featuresImportance[i+1:]\n",
    "        partial = np.delete(embeddings, toRemove, axis=1)\n",
    "        partialSim = 1-pairwise_distances(partial, partial, metric='cosine')\n",
    "        rho = stats.spearmanr(humanSim.flatten(), partialSim.flatten(), nan_policy='omit').statistic\n",
    "        a.append(rho)\n",
    "    indexMax = np.argsort(a)[-1]\n",
    "    featuresToKeep = featuresImportance[:indexMax+1]\n",
    "\n",
    "    return featuresToKeep, a[indexMax]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c36fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = []\n",
    "w2 = []\n",
    "sim = []\n",
    "for l in pMathsDataFiltered.itertuples():\n",
    "    if l.PresentationOrder == 'word1_word2':\n",
    "        w1.append(l.word1)\n",
    "        w2.append(l.word2)\n",
    "    else:\n",
    "        w1.append(l.word2)\n",
    "        w2.append(l.word1)\n",
    "    sim.append(l.Answer)\n",
    "pMathsDataOrder = pd.DataFrame({'word1': w1, 'word2': w2, 'answer': sim})\n",
    "pMathsDataOrderAgg = pMathsDataOrder.groupby(['word1', 'word2']).mean().reset_index()\n",
    "\n",
    "humanSim = pd.pivot(pMathsDataOrderAgg, index='word1', columns='word2', values='answer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed868447",
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresToKeep, corr = prune(humanSim, vectors.loc[humanSim.index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f48538c",
   "metadata": {},
   "outputs": [],
   "source": [
    "newEmbeddings = vectors[[str(i+1) for i in featuresToKeep]].copy()\n",
    "newSim = pd.DataFrame(cosine_similarity(newEmbeddings)).set_index(vectors.index).rename(columns={i: vectors.index[i] for i in range(988)})\n",
    "newSimStack = newSim.stack().reset_index().rename(columns={'word': 'word1', 'level_1': 'word2', 0: 'PrunedSim'}).set_index(['word1','word2'])\n",
    "pMathsDataAggPruned = pMathsDataAgg.join(newSimStack, on=['word1', 'word2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6971cdd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "newEmbeddings.to_csv('prunedEmbeddingsAll.csv')\n",
    "newEmbeddings.loc[pMathsDataOrderAgg.word1.unique()].to_csv('prunedEmbeddings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f584b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "pMathsDataAggPruned = quantileCut(pMathsDataAggPruned, ['PrunedSim'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d79384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spearman's rank correlation analysis\n",
    "res = stats.spearmanr(pMathsDataAggPruned.AnswerBins, pMathsDataAggPruned.PrunedSimBins)\n",
    "display(Markdown(rf\"Spearman's $r_s$ coefficient: {res.statistic:.2f} (p = {res.pvalue:.2e})<br>$r_s^2$ = {res.statistic**2:.3f}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e5aeab",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = rankOLS(pMathsDataAggPruned.AnswerBins, pMathsDataAggPruned.PrunedSimBins)\n",
    "results = model.fit()\n",
    "results.summary2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b9f6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.JointGrid(pMathsDataAggPruned, x=\"PrunedSimBins\", y=\"AnswerBins\")\n",
    "g.plot_joint(sns.lineplot)\n",
    "g.plot_marginals(sns.histplot, kde=True)\n",
    "g.ax_joint.axvline(x=0, linestyle='--', color='.4')\n",
    "#g.set_axis_labels(\"GloVe similarity\", \"Human similarity\")\n",
    "g.set_axis_labels(\"\",\"\")\n",
    "# g.ax_joint.text(0.7, 0.5, f\"N = {len(pMathsDataAgg.Answer)}\\nSpearman's $r_s$ = {res.statistic:.2f}\\np < .001\", \n",
    "#                 horizontalalignment='center', verticalalignment='center', bbox={'edgecolor':'black', 'facecolor':'none'})\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(figWidth/1.2, figWidth*ratio)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6bdd1f0",
   "metadata": {},
   "source": [
    "### Dependency on education level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ad714d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotateLevel(data, **kws):\n",
    "    res = stats.spearmanr(data.Answer, data.GloVeSimilarity)\n",
    "    ax = plt.gca()\n",
    "    ax.text(0.7, 0.5, f\"Spearman's $r_s$ = {res.statistic:.2f}\\nN = {len(data)}\\np = {res.pvalue:.2e}\", \n",
    "        horizontalalignment='center', verticalalignment='center', bbox={'edgecolor':'black', 'facecolor':'none'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4da252b",
   "metadata": {},
   "source": [
    "#### Dependency on self-reported education level of participants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d10840",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100\n",
    "pMathsDataAggLevel = pMathsDataFiltered.groupby(['Question', 'EdLevel']).mean(numeric_only=True)\n",
    "pMathsDataAggLevel['GloVeSimilarityBins'] = pMathsDataAggLevel.GloVeSimilarity.apply(lambda x: np.floor(x*n)/n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1feb0ef5",
   "metadata": {},
   "source": [
    "For each participant, compute correlation between judgements and GloVe predictions. Then test whether self-reported education level has an effect on the correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35b0e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "edLevelCol = ['SubjectID', 'EdLevelId', 'Correlation']\n",
    "\n",
    "allEdData = []\n",
    "for sub, subData in pMathsDataFiltered.groupby('SubID'):\n",
    "    res = stats.spearmanr(subData.GloVeSimilarity, subData.Answer)\n",
    "    edLevel = subData.EdLevelId.unique()[0]\n",
    "    allEdData.append([sub, edLevel, res.statistic])\n",
    "\n",
    "edLevelData = pd.DataFrame(allEdData, columns=edLevelCol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120d55f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# anova\n",
    "model = ols(\"Correlation ~ C(EdLevelId, Sum)\", data=edLevelData)\n",
    "results = model.fit()\n",
    "anova_lm(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e718d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tukey = tukeyhsd(endog=edLevelData.Correlation, groups=edLevelData.EdLevelId)\n",
    "print(tukey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b38544a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.violinplot(edLevelData, y=\"Correlation\", x=\"EdLevelId\")\n",
    "# ax.set(ylabel=\"Within participant correlation between similarity judgements and GloVe predicted cosine similarity\", \n",
    "#        xlabel=\"Self-reported education level\")\n",
    "ax.set(ylabel=\"\", xlabel=\"\")\n",
    "ax.set_xticklabels(labels=edLevelOrder, rotation=45, ha='right')\n",
    "plt.grid(axis='x')\n",
    "annotator = Annotator(ax, [(2,5),(2,7),(2,8),(2,9),(3,9),(6,9)], plot='violinplot', data=edLevelData, \n",
    "                      y=\"Correlation\", x=\"EdLevelId\")\n",
    "annotator.set_custom_annotations([\"*\", \"**\", \"**\", \"****\", \"**\", \"**\"])\n",
    "annotator.annotate()\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(figWidth/1.2, figWidth*ratio)\n",
    "for item in ([ax.title, ax.xaxis.label, ax.yaxis.label] +\n",
    "             ax.get_xticklabels() + ax.get_yticklabels()):\n",
    "    item.set_fontsize(14)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b227e5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = rankOLS(edLevelData.Correlation, edLevelData.EdLevelId)\n",
    "result = model.fit()\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2cf7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.pointplot(edLevelData, y=\"Correlation\", x=\"EdLevelId\")\n",
    "ax.set(ylabel=\"Within participant correlation between similarity judgements and\\nGloVe predicted cosine similarity\", \n",
    "       xlabel=\"Self-reported education level\", xticklabels=edLevelOrder)\n",
    "ax.set_xticklabels(labels=edLevelOrder, rotation=45)\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93fe258e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.boxplot(edLevelData, y=\"Correlation\", x=\"EdLevelId\")\n",
    "ax.set(xlabel=\"Within participant correlation between similarity judgements and GloVe predicted cosine similarity\", \n",
    "       ylabel=\"Self-reported education level\", yticklabels=edLevelOrder)\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5eee9d1",
   "metadata": {},
   "source": [
    "#### Quality of GloVe fit depending on education level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3869f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "nonMathsData = pd.read_csv('../Data/pairSim/French/pairSim_50_nonmaths.csv', encoding='utf-8', index_col='PairID')\n",
    "allData = pd.read_csv('../Data/pairSim/French/pairSim_50_all.csv', encoding='utf-8', index_col='PairID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55346c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# global fit global corpus\n",
    "globalFit = pMathsDataFiltered.join(allData, on=\"Question\", lsuffix=\"_part\")\n",
    "model = rankOLS(globalFit.Similarity, globalFit.Answer)\n",
    "results = model.fit()\n",
    "results.summary2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76714a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# global fit non-maths corpus\n",
    "nonmathsFit = pMathsDataFiltered.join(nonMathsData, on=\"Question\", lsuffix=\"_part\")\n",
    "model = rankOLS(nonmathsFit.Similarity, nonmathsFit.Answer)\n",
    "results = model.fit()\n",
    "results.summary2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c22982e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# global fit maths corpus\n",
    "mathsFit = pMathsDataFiltered.join(stimData, on=\"Question\", lsuffix=\"_part\")\n",
    "model = rankOLS(mathsFit.Similarity, mathsFit.Answer)\n",
    "results = model.fit()\n",
    "results.summary2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177ee04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# education level\n",
    "\n",
    "mathsR = []\n",
    "nonMathsR = []\n",
    "allR = []\n",
    "edLevel = []\n",
    "\n",
    "for level, levelData in pMathsDataFiltered.groupby('EdLevelId'):\n",
    "    edLevel.append(int(level))\n",
    "    for sims, simList in zip([stimData, nonMathsData, allData], [mathsR, nonMathsR, allR]):\n",
    "        dat = levelData.join(sims, on=\"Question\", rsuffix=\"Sim\")\n",
    "        model = rankOLS(dat.Answer, dat.Similarity)\n",
    "        result = model.fit()\n",
    "        simList.append(result.rsquared)\n",
    "        \n",
    "        \n",
    "diffGloVeEdLevel = pd.DataFrame(index=edLevel, data={'Maths Corpus': mathsR, 'Non Maths Corpus': nonMathsR, 'All Corpora': allR})\n",
    "diffGloVeEdLevel = pd.DataFrame(diffGloVeEdLevel.stack()).rename(columns={0: 'Fit'})\n",
    "diffGloVeEdLevel = diffGloVeEdLevel.reset_index().rename(columns={'level_0': 'Level', 'level_1': 'Training Corpus'})\n",
    "diffGloVeEdLevel['Fit'] = np.array(diffGloVeEdLevel.Fit)*100\n",
    "diffGloVeEdLevel['NoiseCeiling'] = [noiseCeiling[x]*100 for x in diffGloVeEdLevel.Level]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07032892",
   "metadata": {},
   "outputs": [],
   "source": [
    "# level of acquisition of the pair\n",
    "\n",
    "mathsR = []\n",
    "nonMathsR = []\n",
    "allR = []\n",
    "wordLevel = []\n",
    "\n",
    "for level, levelData in pMathsDataFiltered.groupby('PairLevel'):\n",
    "    wordLevel.append(int(level))\n",
    "    for sims, simList in zip([stimData, nonMathsData, allData], [mathsR, nonMathsR, allR]):\n",
    "        dat = levelData.join(sims, on=\"Question\", rsuffix=\"Sim\")\n",
    "        model = rankOLS(dat.Answer, dat.Similarity)\n",
    "        result = model.fit()\n",
    "        simList.append(result.rsquared)\n",
    "        \n",
    "        \n",
    "diffGloVeWordLevel = pd.DataFrame(index=wordLevel, data={'Maths Corpus': mathsR, 'Non Maths Corpus': nonMathsR, 'All Corpora': allR})\n",
    "diffGloVeWordLevel = pd.DataFrame(diffGloVeWordLevel.stack()).rename(columns={0: 'Fit'})\n",
    "diffGloVeWordLevel = diffGloVeWordLevel.reset_index().rename(columns={'level_0': 'Level', 'level_1': 'Training Corpus'})\n",
    "diffGloVeWordLevel['Fit'] = np.array(diffGloVeWordLevel.Fit)*100\n",
    "diffGloVeWordLevel['NoiseCeiling'] = [noiseCeilingWordLevel[x]*100 for x in diffGloVeWordLevel.Level]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334294ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# article fig\n",
    "ax = sns.pointplot(diffGloVeEdLevel, x='Level', y='Fit', hue='Training Corpus')#, sort=False)\n",
    "sns.lineplot(diffGloVeEdLevel, x='Level', y='NoiseCeiling',legend=False, linestyle='--', color='grey', sort=False, ax=ax,\n",
    "            label='Noise ceiling')\n",
    "ax.set(ylim=[0,60], ylabel='', xlabel='',\n",
    "       xticks=[i for i in range(len(edLevelOrder))])\n",
    "# ax.set(ylim=[0,100], ylabel='% of explained variance', xlabel='Education level',\n",
    "#        xticks=[i for i in range(len(edLevelOrder))])\n",
    "ax.set_xticklabels(edLevelOrder, rotation = 45, ha='right')\n",
    "leg = plt.legend()\n",
    "leg.remove()\n",
    "plt.grid(axis='x')\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(figWidth/1.6, ratio*figWidth*1.2)\n",
    "for item in ([ax.title, ax.xaxis.label, ax.yaxis.label] +\n",
    "             ax.get_xticklabels() + ax.get_yticklabels()):\n",
    "    item.set_fontsize(14)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbadd0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = diffGloVeEdLevel.pivot(index='Level', columns='Training Corpus', values='Fit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c25901",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0230c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.spearmanr(tmp.index, tmp['Maths Corpus'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5592fedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.spearmanr(tmp.index, tmp['Non Maths Corpus'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d1f7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.spearmanr(tmp.index, tmp['All Corpora'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438d7ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# article fig\n",
    "ax = sns.pointplot(diffGloVeWordLevel, x='Level', y='Fit', hue='Training Corpus')#, sort=False)\n",
    "sns.lineplot(diffGloVeWordLevel, x='Level', y='NoiseCeiling',legend=False, linestyle='--', color='grey', sort=False, ax=ax,\n",
    "            label='Noise ceiling')\n",
    "ax.set(ylim=[0,60], ylabel='', xlabel='',\n",
    "       xticks=[i for i in range(len(wordLevelOrder))])\n",
    "# ax.set(ylim=[0,100], ylabel='% of explained variance', xlabel='Estimated level of acquisition of words of the pair',\n",
    "#        xticks=[i for i in range(len(wordLevelOrder))])\n",
    "ax.set_xticklabels(wordLevelOrder, rotation = 45, ha='right')\n",
    "leg = plt.legend()\n",
    "leg.remove()\n",
    "plt.grid(axis='x')\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(figWidth/1.6, ratio*figWidth*1.17)\n",
    "for item in ([ax.title, ax.xaxis.label, ax.yaxis.label] +\n",
    "             ax.get_xticklabels() + ax.get_yticklabels()):\n",
    "    item.set_fontsize(16)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e2c2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = diffGloVeWordLevel.pivot(index='Level', columns='Training Corpus', values='Fit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763fc9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5789827a",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.wilcoxon(tmp['Maths Corpus'], tmp['All Corpora'], alternative='greater', method='exact')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3ea469",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.wilcoxon(tmp['Maths Corpus'], tmp['Non Maths Corpus'], alternative='greater', method='exact')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c9619b",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.spearmanr(tmp.index, tmp['Maths Corpus'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365673b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.spearmanr(tmp.index, tmp['Non Maths Corpus'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aae111d",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.spearmanr(tmp.index, tmp['All Corpora'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ba86f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = pMathsDataFiltered.loc[pMathsDataFiltered.PairLevel.isin([1,2])]\n",
    "\n",
    "# education level\n",
    "\n",
    "mathsR = []\n",
    "nonMathsR = []\n",
    "allR = []\n",
    "edLevel = []\n",
    "\n",
    "for level, levelData in tmp.groupby('EdLevelId'):\n",
    "    edLevel.append(int(level))\n",
    "    for sims, simList in zip([stimData, nonMathsData, allData], [mathsR, nonMathsR, allR]):\n",
    "        dat = levelData.join(sims, on=\"Question\", rsuffix=\"Sim\")\n",
    "        model = rankOLS(dat.Answer, dat.Similarity)\n",
    "        result = model.fit()\n",
    "        simList.append(result.rsquared)\n",
    "        \n",
    "        \n",
    "tmpDiffGloVeEdLevel = pd.DataFrame(index=edLevel, data={'Maths Corpus': mathsR, 'Non Maths Corpus': nonMathsR, 'All Corpora': allR})\n",
    "tmpDiffGloVeEdLevel = pd.DataFrame(tmpDiffGloVeEdLevel.stack()).rename(columns={0: 'Fit'})\n",
    "tmpDiffGloVeEdLevel = tmpDiffGloVeEdLevel.reset_index().rename(columns={'level_0': 'Level', 'level_1': 'Training Corpus'})\n",
    "tmpDiffGloVeEdLevel['Fit'] = np.array(tmpDiffGloVeEdLevel.Fit)*100\n",
    "tmpDiffGloVeEdLevel['NoiseCeiling'] = [noiseCeiling[x]*100 for x in tmpDiffGloVeEdLevel.Level]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9eca873",
   "metadata": {},
   "outputs": [],
   "source": [
    "# article fig\n",
    "ax = sns.pointplot(tmpDiffGloVeEdLevel, x='Level', y='Fit', hue='Training Corpus')#, sort=False)\n",
    "ax.set(ylim=[0,60], ylabel='', xlabel='',\n",
    "       xticks=[i for i in range(len(edLevelOrder))])\n",
    "# ax.set(ylim=[0,100], ylabel='% of explained variance', xlabel='Education level',\n",
    "#        xticks=[i for i in range(len(edLevelOrder))])\n",
    "ax.set_xticklabels(edLevelOrder, rotation = 45, ha='right')\n",
    "leg = plt.legend()\n",
    "leg.remove()\n",
    "plt.grid(axis='x')\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(figWidth/1.6, ratio*figWidth*1.2)\n",
    "for item in ([ax.title, ax.xaxis.label, ax.yaxis.label] +\n",
    "             ax.get_xticklabels() + ax.get_yticklabels()):\n",
    "    item.set_fontsize(14)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5df72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = tmpDiffGloVeEdLevel.pivot(index='Level', columns='Training Corpus', values='Fit')\n",
    "len(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7330f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.spearmanr(tmp.index, tmp['Maths Corpus'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc8a5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.spearmanr(tmp.index, tmp['Non Maths Corpus'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2ec4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.spearmanr(tmp.index, tmp['All Corpora'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4620082",
   "metadata": {},
   "source": [
    "## Optimisation of number of dimensions of GloVe vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c2e03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "GloVeDims = []\n",
    "\n",
    "indices = [i for i in range(1,50)] + [i for i in range(50,501,50)]\n",
    "\n",
    "for i in indices:\n",
    "    for corpus in [\"maths\", \"nonmaths\", \"all\"]:\n",
    "        dat = pd.read_csv(f'../Data/pairSim/French/pairSim_{i}_{corpus}.csv', encoding='utf-8')\n",
    "        dat['NumberDim'] = [i]*len(dat)\n",
    "        dat['TrainingCorpus'] = [corpus]*len(dat)\n",
    "        GloVeDims.append(dat)\n",
    "        \n",
    "GloVeDims = pd.concat(GloVeDims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35e16c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = []\n",
    "corpus = []\n",
    "nDims = []\n",
    "\n",
    "for (n, c), corpusData in GloVeDims.groupby(['NumberDim', 'TrainingCorpus']):\n",
    "        nDims.append(n)\n",
    "        dat = pMathsDataFiltered.join(corpusData.set_index('PairID'), on=\"Question\", rsuffix=\"Sim\")\n",
    "        corpus.append(c)\n",
    "        model = rankOLS(dat.Answer, dat.Similarity)\n",
    "        result = model.fit()\n",
    "        r.append(result.rsquared)\n",
    "        \n",
    "        \n",
    "GloVeDimsSubs = pd.DataFrame(data={'NumberDim': nDims, 'TrainingCorpus': corpus, 'Fit': np.array(r)*100})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efaab76",
   "metadata": {},
   "outputs": [],
   "source": [
    "GloVeDimsSubs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5e1c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# article fig\n",
    "ax = sns.lineplot(GloVeDimsSubs.loc[GloVeDimsSubs.TrainingCorpus == \"maths\"], x=\"NumberDim\", y=\"Fit\")\n",
    "ax.axhline(y=noiseCeiling['Global']*100, color='grey', linestyle='--')\n",
    "ax.set(xlabel=\"\", ylabel=\"\", ylim=[0,60])\n",
    "ax.vlines(x=50, ymin=0, ymax=float(GloVeDimsSubs.loc[(GloVeDimsSubs.TrainingCorpus == \"maths\") & (GloVeDimsSubs.NumberDim == 50)].Fit), colors='.4')\n",
    "#ax.set(ylim=[0,100], ylabel=\"% of explained variance\", xlabel=\"Number of dimensions of GloVe vectors\")\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(figWidth/1.6, ratio*figWidth/1.6*1.257)\n",
    "for item in ([ax.title, ax.xaxis.label, ax.yaxis.label] +\n",
    "             ax.get_xticklabels() + ax.get_yticklabels()):\n",
    "    item.set_fontsize(12)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975a93e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.relplot(GloVeDimsSubs, x=\"NumberDim\", y=\"Fit\", col=\"TrainingCorpus\", kind='line')\n",
    "g.refline(y=noiseCeiling['Global']*100, label='Noise Ceiling')\n",
    "g.set(ylim=[0,50], xlabel=\"\", ylabel=\"\")\n",
    "#g.set(ylim=[0,100], ylabel=\"% of explained variance\", xlabel=\"Number of dimensions of GloVe vectors\")\n",
    "leg = plt.legend(bbox_to_anchor=[1.4,0.5])\n",
    "leg.remove()\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
