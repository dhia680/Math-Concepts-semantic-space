{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c3f2a6b",
   "metadata": {},
   "source": [
    "# MathsSim experiment analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc0555b",
   "metadata": {},
   "source": [
    "Analysis of the data collected with the MathsSim online experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d388a6",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7e26f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", UserWarning)\n",
    "warnings.simplefilter('ignore', FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b8c792",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import seaborn as sns\n",
    "from statannotations.Annotator import Annotator # https://github.com/trevismd/statannotations/tree/master\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.weightstats import ttest_ind\n",
    "from statsmodels.stats.anova import anova_lm\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd as tukeyhsd\n",
    "from scipy import stats\n",
    "from scipy.stats import rankdata\n",
    "from scipy.optimize import curve_fit\n",
    "from scikit_posthocs import posthoc_dunn\n",
    "from sklearn.metrics import pairwise_distances \n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import ast\n",
    "from tqdm.notebook import tqdm\n",
    "from IPython.display import display, Markdown\n",
    "import os\n",
    "import subprocess\n",
    "from shutil import which"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96cca2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "custom = {'grid.color': '.8', 'axes.edgecolor': 'black', 'axes.spines.top': False, 'axes.spines.right': False, 'figure.figsize': (11.7,8.27), 'font.size':11, 'font.family': 'Arial', 'font.sans-serif': 'Arial'}\n",
    "sns.set_theme(style=\"whitegrid\", rc=custom)\n",
    "plt.rcParams['svg.fonttype'] = 'none'\n",
    "figWidth = 7.677165 # 19.5cm pour PLOS\n",
    "ratio = 8.27/11.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71c80bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def rankOLS(y,X, **kws):\n",
    "    X = np.array(X)\n",
    "    if len(np.shape(X)) == 1:\n",
    "        X = np.reshape(X, (1,len(X)))\n",
    "    rankx = np.transpose(np.array([rankdata(x) for x in X]))\n",
    "    ranky = rankdata(y)\n",
    "    rankxconst = sm.add_constant(rankx)\n",
    "    model = sm.OLS(endog=ranky, exog=rankxconst, **kws)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0794023b",
   "metadata": {},
   "outputs": [],
   "source": [
    "subData = pd.read_csv('../Data/subDataEnglish.csv', encoding='utf-8', index_col='SubID')\n",
    "expData = pd.read_csv('../Data/expDataEnglish.csv', encoding='utf-8')\n",
    "stimData = pd.read_csv('../Data/pairSim/English/pairSim_50_maths.csv', encoding='utf-8', index_col='PairID')\n",
    "vocData = pd.read_csv('../Data/finalVocab_English_preprocessed.csv', encoding='utf-8', index_col='word',\n",
    "                      converters={'grammaticalForm': ast.literal_eval}, dtype={'mathsFrequency': float, 'nonMathsFrequency': float})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029e7f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "EdLevelToId = {'Bac+2':5, 'Bac+5 (master)':8, 'Bac+3 (licence)':6, 'Bac+4':7, \n",
    "                'Bac':3, 'Primaire':0, 'Bac+1':4, 'Bac+8 (doctorat)':9, 'Lycée':2, 'Collège':1}\n",
    "edLevelOrder = ['Primary school', 'Medium school', 'High school', 'High school diploma', '1st year of college', '2nd year of college (bachelor)', '3rd year of college (licence)', '4th year of college', 'Graduate (master)', 'Graduate (PhD)']\n",
    "edLevelOrderTwoLines = ['Primary school', 'Medium school', 'High school', 'High school diploma', '1st year of college', '2nd year of college\\n(bachelor)', '3rd year of college\\n(licence)', '4th year of college', 'Graduate\\n(master)', 'Graduate\\n(PhD)']\n",
    "wordLevelOrder = ['Primary school', '6-7th grade', '8-9th grade', '10th grade', '11-12th grade', 'Bachelor', 'Licence', 'Master']\n",
    "subData['EdLevelId'] = [EdLevelToId[l] for l in subData.EdLevel]\n",
    "subData = subData[['Sex', 'Age', 'Major', 'EdLevelId', 'EdLevel', 'SelfAssessment', 'StimLevel']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f143042",
   "metadata": {},
   "outputs": [],
   "source": [
    "# translate labels into English\n",
    "EdLevel_FrToEn = {}\n",
    "for i, x in enumerate(['Primaire', 'Collège', 'Lycée', 'Bac', 'Bac+1', 'Bac+2', 'Bac+3 (licence)', 'Bac+4', 'Bac+5 (master)', 'Bac+8 (doctorat)']):\n",
    "    EdLevel_FrToEn[x] = edLevelOrder[i]\n",
    "\n",
    "WordLevel_FrToEn = {}\n",
    "for i, x in enumerate(['primary', '6-7th grade', '8-9th grade', '10th grade', '11-12th grade', 'bachelor', 'licence', 'master']):\n",
    "    WordLevel_FrToEn[x] = wordLevelOrder[i]\n",
    "\n",
    "vocData['levelName'] = [WordLevel_FrToEn[x.levelName] for x in vocData.itertuples()]\n",
    "subData['EdLevel'] = [EdLevel_FrToEn[x.EdLevel] for x in subData.itertuples()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dca557b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exclude participants\n",
    "toExclude = []\n",
    "for part in toExclude:\n",
    "    expData = expData.loc[expData.SubID != part].copy()\n",
    "    subData.drop(index=part, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190eec40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exclude judgements for pairs of level >  given by participants of ed level bac\n",
    "tmp = expData.join(subData, on=\"SubID\").join(stimData, on='Question')\n",
    "toDelete = tmp[(tmp.EdLevel == 'Bac') & (tmp.Level >= 5)].index\n",
    "expData.drop(index=toDelete, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959d4d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = expData.join(subData, on=\"SubID\").join(stimData, on=\"Question\").join(vocData, on=\"Question\")\n",
    "df.rename(columns={'StimLevel': 'SubLevel', 'Level': 'PairLevel', 'levelId': 'WordLevelId', 'levelName': 'WordLevelName'}, inplace=True)\n",
    "df.drop(['metaMaths', 'tooPolysemic', 'grammaticalForm', 'mathsFrequency', 'nonMathsFrequency'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae68ac5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5728c53",
   "metadata": {},
   "source": [
    "## Demographic data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb02d30",
   "metadata": {},
   "source": [
    "### Data summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2964e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "subData['Sex'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e0b592",
   "metadata": {},
   "outputs": [],
   "source": [
    "subData['Age'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c117db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "subData['Major'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1295b808",
   "metadata": {},
   "outputs": [],
   "source": [
    "subData['EdLevel'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c223d1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "subData['SelfAssessment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0195a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(subData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294cc4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.spearmanr(subData.SelfAssessment, subData.EdLevelId)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f308ae",
   "metadata": {},
   "source": [
    "### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6d62c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "majorsOrder = [\"Mathematics\", \"Statistics\", \"Economics\", \"Engineering\", \"Natural Science\", \"Health and Life Science\", \"Psychology\", \"Humanities\", \"Law\", \"None\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a559544",
   "metadata": {},
   "outputs": [],
   "source": [
    "# distribution of education level\n",
    "ax = sns.countplot(data=subData, x=\"EdLevel\", color=sns.color_palette()[0], order=edLevelOrder)\n",
    "ax.set(xlabel=\"Last classes followed in maths\")\n",
    "ax.tick_params(axis='x', rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83b86d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# distribution of self-assessed maths level\n",
    "ax = sns.countplot(data=subData, x=\"SelfAssessment\", color=sns.color_palette()[0])\n",
    "ax.set(xlabel=\"Self-assessed maths-level\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd7b726",
   "metadata": {},
   "outputs": [],
   "source": [
    "# distribution of majors\n",
    "ax = sns.countplot(data=subData, x=\"Major\", color=sns.color_palette()[0], order=majorsOrder)\n",
    "ax.set(xlabel=\"College Major\")\n",
    "ax.tick_params(axis='x', rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2717f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# self-assessed maths level against education level\n",
    "ax = sns.barplot(data=subData, x=\"EdLevel\", y=\"SelfAssessment\", errorbar=\"sd\", color=sns.color_palette()[0],\n",
    "                order=edLevelOrder)\n",
    "ax.set(xlabel=\"Last classes followed in maths\", ylabel=\"Self-assessed maths level\",\n",
    "       title=\"Self-assessed maths level against last classes followed in maths\",\n",
    "       ylim=[0,10])\n",
    "ax.tick_params(axis='x', rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad44bde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# self-assessed maths level against major\n",
    "ax = sns.barplot(data=subData, x=\"Major\", y=\"SelfAssessment\", errorbar=\"sd\", color=sns.color_palette()[0],\n",
    "                order=majorsOrder)\n",
    "ax.set(xlabel=\"College Major\", ylabel=\"Self-assessed maths level\", title=\"Self-assessed maths level against college major\",\n",
    "       ylim=[0,10])\n",
    "ax.tick_params(axis='x', rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494665e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# self-assessed maths level against age\n",
    "ax = sns.barplot(data=subData, x=\"Age\", y=\"SelfAssessment\", errorbar=\"sd\", color=sns.color_palette()[0],\n",
    "                order=[\"18-25\", \"25-40\", \"40-60\", \"60-more\"])\n",
    "ax.set(xlabel=\"Age\", ylabel=\"Self-assessed maths level\", title=\"Self-assessed maths level against age\",\n",
    "       ylim=[0,10])\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "366a822d",
   "metadata": {},
   "source": [
    "## Voc knowledge analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcdce29c",
   "metadata": {},
   "source": [
    "Questions:\n",
    "- Overall, is our classification of words correct? Does it fit with the actual education of participants?\n",
    "- Are some words misclassified?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cda850b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data\n",
    "vData = df.loc[df.Trial == 'VocKnowledge'].copy()\n",
    "vData.drop(['Trial', 'RT', 'PresentationOrder', 'Training', 'SubLevel', 'word1', 'word2', 'PairLevel', 'Similarity', 'EuclideanDistance'], \n",
    "           axis=1, inplace=True)\n",
    "vData['Answer'] = vData.Answer.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d36ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "vData"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d74719",
   "metadata": {},
   "source": [
    "### Analysis of the average knowledge for each word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6e0f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "meanKnowledge = vData.groupby('Question').mean(numeric_only=True)\n",
    "meanKnowledge['Count'] = vData.value_counts('Question')\n",
    "meanKnowledge['WordLevelName'] = meanKnowledge.join(vocData, on='Question').levelName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e6daae",
   "metadata": {},
   "outputs": [],
   "source": [
    "meanKnowledge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7bcdc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "saveVoc = False\n",
    "\n",
    "if saveVoc:\n",
    "    df = meanKnowledge.copy()\n",
    "    df['STD'] = [np.std(vData[vData.Question == x].Answer) for x in df.index]\n",
    "    df.to_excel('vocAnalyses/vocKnowledge.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49870ec9",
   "metadata": {},
   "source": [
    "#### Relation between average knowledge and proposed classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe8362d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spearman's rank correlation analysis\n",
    "res = stats.spearmanr(meanKnowledge.WordLevelId, meanKnowledge.Answer)\n",
    "display(Markdown(rf\"Spearman's $r_s$ coefficient: {res.statistic:.3f} (p = {res.pvalue:.2e})\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465c9f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordLevelOrder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8fa82d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.pointplot(meanKnowledge, x=\"WordLevelName\", y=\"Answer\", errorbar='sd',\n",
    "                 order=wordLevelOrder)\n",
    "ax.set(ylim=[-0.1,8.1], yticks=[i for i in range(9)],\n",
    "      xlabel=\"Estimated level of acquisition\", ylabel=\"Mean knowledge rating per word (from 0 to 8)\")\n",
    "ax.text(0.5, 0.5, f\"Spearman's $r_s$ = {res.statistic:.2f}\\np = {res.pvalue:.2e}\", \n",
    "       horizontalalignment='center', verticalalignment='center', bbox={'edgecolor':'black', 'facecolor':'none'})\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8877cdfe",
   "metadata": {},
   "source": [
    "#### Distribution of average knowledge across words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a21574",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.violinplot(meanKnowledge, x=\"Answer\", y=\"WordLevelName\", cut=0, scale='count', \n",
    "                    order=wordLevelOrder, color=sns.color_palette()[0])\n",
    "b = set(list(ax.get_children()))\n",
    "ax = sns.pointplot(meanKnowledge, x=\"Answer\", y=\"WordLevelName\", errorbar=None, \n",
    "              order=wordLevelOrder, color=sns.color_palette()[5], markers='x', ax=ax)\n",
    "f = set(list(ax.get_children()))-b\n",
    "for e in f:\n",
    "    e.set_zorder(100)\n",
    "ax.set(xlim=[-0.1,8.1], xticks=[i for i in range(9)],\n",
    "       xlabel=\"Mean knowledge rating per word (from 0 to 8)\", ylabel=\"Estimated level of acquisition\")\n",
    "for level, levelData in meanKnowledge.groupby('WordLevelId'):\n",
    "    ax.text(0.5,level,f\"n = {len(levelData)}\", horizontalalignment='center')\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced622f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.displot(meanKnowledge, x=\"Answer\", col=\"WordLevelName\", kind=\"kde\",\n",
    "               col_order=wordLevelOrder, col_wrap=4, facet_kws={'sharey':False})\n",
    "g.set_axis_labels(\"Mean knowledge rating per word (from 0 to 8)\", \"Density\")\n",
    "g.set_titles(col_template=\"Estimated level of acquisition = {col_name}\")\n",
    "g.set(xlim=(-0.1, 8.1), xticks=[i for i in range(9)])\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f205c4bb",
   "metadata": {},
   "source": [
    "### Variation of the average knowledge with self-reported maths education"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85550ed",
   "metadata": {},
   "source": [
    "#### Redo the as above for each self-report maths education level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca023e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "meanKnowledgeLevelDep = vData.groupby(['Question', 'EdLevel']).mean(numeric_only=True)\n",
    "meanKnowledgeLevelDep['Count'] = vData.groupby(['Question', 'EdLevel']).count().SubID\n",
    "meanKnowledgeLevelDep['WordLevelName'] = meanKnowledgeLevelDep.join(vocData, on='Question').levelName\n",
    "for val in ['Question', 'EdLevel']:\n",
    "    meanKnowledgeLevelDep[val] = meanKnowledgeLevelDep.index.get_level_values(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c81e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "meanKnowledgeLevelDep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b6421d",
   "metadata": {},
   "source": [
    "##### Relation between average knowledge and proposed classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bed9bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotateCorrelation(data, x=None, y=None, x_an=None, y_an=None, **kws):\n",
    "    res = stats.spearmanr(data[x], data[y])\n",
    "    ax = plt.gca()\n",
    "    ax.text(x_an, y_an, f\"Spearman's $r_s$ = {res.statistic:.2f}\\np = {res.pvalue:.2e}\", \n",
    "        horizontalalignment='left', verticalalignment='center', bbox={'edgecolor':'black', 'facecolor':'none'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709ba277",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.catplot(meanKnowledgeLevelDep, x=\"WordLevelName\", y=\"Answer\", col=\"EdLevel\", errorbar='sd', kind='point',\n",
    "                order=wordLevelOrder, col_order=edLevelOrder, col_wrap=4)\n",
    "g.map_dataframe(annotateCorrelation, x=\"WordLevelId\", y=\"Answer\", x_an=.1, y_an=.5)\n",
    "g.set(ylim=[-0.1,8.1], yticks=[i for i in range(9)],\n",
    "      xlabel=\"Estimated level of acquisition\", ylabel=\"Mean knowledge rating per word (from 0 to 8)\")\n",
    "g.set_titles(col_template=\"Self-reported education level: {col_name}\")\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a959dfd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "meanKnowledgeLevelDep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace1df05",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax= sns.pointplot(meanKnowledgeLevelDep, x=\"EdLevel\", y=\"Answer\", hue=\"WordLevelName\", \n",
    "                   order=edLevelOrder, hue_order=wordLevelOrder, palette=['#1b9e77','#d95f02','#7570b3','#e7298a','#66a61e','#e6ab02','#a6761d','#666666'])\n",
    "ax.set(xlabel=\"\", ylabel=\"\")\n",
    "ax.set_xticklabels(labels=edLevelOrder, rotation = 30, ha='right')\n",
    "ax.legend(title=\"Word grade\", loc='center right', bbox_to_anchor=[1.38,.5])\n",
    "#ax.text(ax.get_xlim()[0], ax.get_ylim()[1]+.2, \"Familiarity rating\", size=12, horizontalalignment=\"center\", va=\"bottom\")\n",
    "#ax.text(ax.get_xlim()[1]+.2, ax.get_ylim()[0], \"Participant education level\", size=12, horizontalalignment=\"left\", va=\"center\")\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(figWidth, figWidth*ratio)\n",
    "plt.grid(axis='x')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f4261f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# article fig\n",
    "ax= sns.pointplot(meanKnowledgeLevelDep, y=\"EdLevel\", x=\"Answer\", hue=\"WordLevelName\", dodge=True, \n",
    "                  order=edLevelOrder, hue_order=wordLevelOrder, palette=['#1b9e77','#d95f02','#7570b3','#e7298a','#66a61e','#e6ab02','#a6761d','#666666'])\n",
    "ax.set(xlabel=\"\", ylabel=\"\")\n",
    "ax.set_yticklabels(labels=edLevelOrderTwoLines)\n",
    "leg = ax.legend(title=\"Word grade\", loc='center right', bbox_to_anchor=[1,.5])\n",
    "leg.remove()\n",
    "#ax.text(ax.get_xlim()[0], ax.get_ylim()[1]+.2, \"Familiarity rating\", size=12, horizontalalignment=\"center\", va=\"bottom\")\n",
    "#ax.text(ax.get_xlim()[1]+.2, ax.get_ylim()[0], \"Participant education level\", size=12, horizontalalignment=\"left\", va=\"center\")\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(figWidth/1.4, figWidth*ratio)\n",
    "plt.grid(axis='y')\n",
    "for item in ([ax.title, ax.xaxis.label, ax.yaxis.label] +\n",
    "             ax.get_xticklabels() + ax.get_yticklabels()):\n",
    "    item.set_fontsize(14)\n",
    "#plt.tight_layout()\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f0da4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dff = vData.join(vocData, on='Question', rsuffix=\"_r\")\n",
    "dff['WordLevelId'] = (lambda x: (x-np.mean(x))/np.std(x))((lambda y: rankdata(y))(dff['WordLevelId']))\n",
    "dff['mathsFrequency'] = (lambda x: (x-np.mean(x))/np.std(x))((lambda y: rankdata(y))(dff['mathsFrequency']))\n",
    "dff['EdLevelId'] = (lambda x: (x-np.mean(x))/np.std(x))((lambda y: rankdata(y))(dff['EdLevelId']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35f8040",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ols('Answer ~ WordLevelId * EdLevelId', data=dff)\n",
    "results = model.fit()\n",
    "results.summary2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee9bfd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ols('Answer ~ WordLevelId * mathsFrequency * EdLevelId', data=dff)\n",
    "results = model.fit()\n",
    "results.summary2()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba396bb",
   "metadata": {},
   "source": [
    "### Participant analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d7c990",
   "metadata": {},
   "outputs": [],
   "source": [
    "vDataPerSub = vData.groupby('SubID').mean(numeric_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6aa2809",
   "metadata": {},
   "source": [
    "What is the mean knowledge of a given participant?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463a87ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.kdeplot(vDataPerSub, x=\"Answer\")\n",
    "ax.set(xlim=[-0.1,8.1], xticks=[i for i in range(9)],\n",
    "       xlabel=\"Mean knowledge rating per participant (from 0 to 8)\")\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7487231a",
   "metadata": {},
   "source": [
    " Is it correlated with its self-report education and maths level?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a58249",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = stats.spearmanr(vDataPerSub.EdLevelId, vDataPerSub.Answer)\n",
    "display(Markdown(rf\"Spearman's $r_s$ coefficient: {res.statistic:.2f} (p = {res.pvalue:.2e})\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5868e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.pointplot(vDataPerSub, x=\"EdLevelId\", y=\"Answer\", errorbar='sd')\n",
    "ax.set(ylim=[-0.1,8.1], yticks=[i for i in range(9)],\n",
    "       xlabel=\"Reported education level\", ylabel=\"Mean knowledge rating per participant (from 0 to 8)\",\n",
    "       xticks=[i for i in range(len(edLevelOrder))], xticklabels=edLevelOrder)\n",
    "ax.tick_params(axis='x', rotation=45)\n",
    "ax.text(8.5, 0.5, f\"Spearman's $r_s$ = {res.statistic:.2f}\\nN = {len(vDataPerSub)}\\np = {res.pvalue:.2e}\", \n",
    "        horizontalalignment='center', verticalalignment='center', bbox={'edgecolor':'black', 'facecolor':'none'})\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c332a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(vDataPerSub.SelfAssessment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf7cee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = stats.spearmanr(vDataPerSub.SelfAssessment, vDataPerSub.Answer)\n",
    "display(Markdown(rf\"Spearman's $r_s$ coefficient: {res.statistic:.2f} (p = {res.pvalue:.2e})\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4e96f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.pointplot(vDataPerSub, x=\"SelfAssessment\", y=\"Answer\", errorbar='sd')\n",
    "ax.set(ylim=[-0.1,8.1], yticks=[i for i in range(9)], xticks=[i for i in range(10)],\n",
    "       xlabel=\"Self-assessed maths level (from 1 to 10)\", ylabel=\"Mean knowledge rating per participant (from 0 to 8)\")\n",
    "ax.text(8.5, 0.5, f\"Spearman's $r_s$ = {res.statistic:.2f}\\np = {res.pvalue:.2e}\", \n",
    "        horizontalalignment='center', verticalalignment='center', bbox={'edgecolor':'black', 'facecolor':'none'})\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0769003",
   "metadata": {},
   "source": [
    "## Word similarity analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104330f3",
   "metadata": {},
   "source": [
    "Questions:\n",
    "- Do subjects agree on the similarities of math words? (split-half consistency)\n",
    "- Is GloVe a good model of those similarities?\n",
    "- Do similarities change with education (get refined?? get more similar to Glove??)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a54b850",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data\n",
    "pData = df.loc[df.Trial == 'SimilarityJudgement'].copy()\n",
    "pData.drop(['Trial', 'RT', 'WordLevelId', 'WordLevelName'], \n",
    "           axis=1, inplace=True)\n",
    "pData.rename({'Similarity': 'GloVeSimilarity', 'SubLevel': 'StimLevelCategory'}, axis=1, inplace=True)\n",
    "pData['Training'] = [not i for i in pData.Training] # fix this unintuitive issue\n",
    "pData['Answer'] = pData.Answer.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf69845e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove training data\n",
    "pMathsData = pData.loc[~pData.Training].copy()\n",
    "# remove unanswered questions\n",
    "pMathsDataFiltered = pMathsData.dropna(subset=[\"Answer\"]).copy()\n",
    "# average over participants for each question\n",
    "pMathsDataAgg = pMathsDataFiltered.groupby(\"Question\").mean(numeric_only=True).join(stimData[['word1', 'word2']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f827776f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pMathsDataAgg['MeanKnowledge'] = [np.mean([vData[vData.Question == x.word1].Answer.mean(),vData[vData.Question == x.word2].Answer.mean()]) for x in pMathsDataAgg.itertuples()]\n",
    "pMathsDataAgg['MeanFreq'] = [np.mean([vocData.loc[x.word1].mathsFrequency, vocData.loc[x.word2].mathsFrequency]) for x in pMathsDataAgg.itertuples()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caaac08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pData"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78b0d95",
   "metadata": {},
   "source": [
    "### Sanity checks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2da3e22",
   "metadata": {},
   "source": [
    "#### Training questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd4ebac",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingData = pData.loc[pData.Training]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ceb9119",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.boxplot(trainingData, x=\"Question\", y=\"Answer\")\n",
    "ax.tick_params(axis='x', rotation=45)\n",
    "ax.set(xlabel=\"Training pair\", ylabel=\"Distribution of estimated proximity\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2baf90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.displot(trainingData, x=\"Answer\", col=\"Question\", kde=True,\n",
    "                col_wrap=4, facet_kws={'sharey':False})\n",
    "g.set_titles(col_template='Pair: \"{col_name}\"')\n",
    "g.set(xlabel=\"Estimated proximity\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2582a707",
   "metadata": {},
   "source": [
    "#### Number of presentation of each pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be0ec32",
   "metadata": {},
   "outputs": [],
   "source": [
    "numPres = pMathsDataFiltered.groupby(\"Question\").count()\n",
    "numPresOrder = pMathsDataFiltered.groupby([\"Question\", \"PresentationOrder\"]).count()\n",
    "numPresOrder['Order'] = numPresOrder.index.get_level_values('PresentationOrder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8c38f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.boxplot(numPres, x='SubID', showmeans=True)\n",
    "ax.set(xlabel=\"Number of presentations of each pair\")\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5efb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.histplot(numPres, x='SubID')\n",
    "ax.set(xlabel=\"Number of presentation of each pair\")\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b6a20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.boxplot(numPresOrder, x='SubID', y='Order', showmeans=True)\n",
    "ax.set(xlabel=\"Number of presentations of each pair\")\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608f11fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.histplot(numPresOrder, x='SubID', hue='Order')\n",
    "ax.set(xlabel=\"Number of presentation of each pair\")\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2bcc17",
   "metadata": {},
   "source": [
    "#### Effect of order of presentation of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d62794b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = pMathsData.groupby(['Question', 'PresentationOrder'], as_index=False).mean(numeric_only=True)\n",
    "orderPresentationData = tmp.pivot(index='Question', columns='PresentationOrder', values='Answer')\n",
    "orderPresentationData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2897d25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation test\n",
    "model = ols(\"word2_word1 ~ word1_word2\", data=orderPresentationData)\n",
    "results = model.fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54972ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.regplot(orderPresentationData, x=\"word1_word2\", y=\"word2_word1\", \n",
    "                 line_kws={'color': sns.color_palette()[1]})\n",
    "ax.set(xlabel=\"Mean human judged similarity per pair (word1-word2)\", \n",
    "       ylabel=\"Mean human judged similarity per pair (word2-word1)\")\n",
    "ax.text(0.5, 4.8, f\"$R^2$ = {results.rsquared:.2f}\\nN = {len(orderPresentationData)}\\np = {results.f_pvalue:.2e}\", \n",
    "        horizontalalignment='center', verticalalignment='center', bbox={'edgecolor':'black', 'facecolor':'none'})\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176daf6d",
   "metadata": {},
   "source": [
    "### Overall analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aff9781",
   "metadata": {},
   "source": [
    "#### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca329370",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = pd.read_csv('../Embeddings/English/GloVe/words_vec_50_maths.csv', index_col=\"word\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7830c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairLevelToCat(l):\n",
    "    if l == 0:\n",
    "        return 0\n",
    "    elif l <= 2:\n",
    "        return 2\n",
    "    elif l <= 4:\n",
    "        return 4\n",
    "    elif l <= 5:\n",
    "        return 5\n",
    "    else:\n",
    "        return 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004d9cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add categorical levels of predicted similarities\n",
    "pMathsDataAgg['CategoricalSim'] = ['']*len(pMathsDataAgg)\n",
    "for l, levelData in pMathsDataAgg.groupby(\"PairLevel\"):\n",
    "    level = pairLevelToCat(l)\n",
    "    df = pd.read_csv(f\"../Data/EnglishPairs/selectedPairs_{level}.csv\", index_col=\"PairID\")\n",
    "    for t in levelData.itertuples():\n",
    "        pMathsDataAgg.at[t.Index, 'CategoricalSim'] = df.loc[t.Index].SimCategory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21fbaf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "catSimOrder = [\"Furthest\", \"Orthogonal\", \"Average\", \"Closest\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3c5f47",
   "metadata": {},
   "source": [
    "#### Compute noise ceiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a4354b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossVal(data, other, stimVar, respVar, groups):\n",
    "    a = []\n",
    "    p = []\n",
    "    r2 = []\n",
    "    \n",
    "    for fold, foldData in data.groupby(groups):\n",
    "        \n",
    "        otherData = other[other[groups] != fold]\n",
    "        otherData = otherData.groupby(stimVar).mean(numeric_only=True)\n",
    "        \n",
    "        allData = otherData.join(foldData.set_index(stimVar), how='inner', rsuffix='fold')\n",
    "        allData.dropna(subset=[respVar, respVar+'fold'], how='any', inplace=True)\n",
    "        \n",
    "        if len(allData[respVar].unique()) >= 2 and len(allData[respVar+'fold'].unique()) >= 2:\n",
    "        \n",
    "            p.append(len(foldData)-len(allData))\n",
    "            \n",
    "            model = rankOLS(allData[respVar+'fold'], allData[respVar], missing='drop')\n",
    "            result = model.fit()\n",
    "            r2.append(result.rsquared)\n",
    "            a.append(result.params[1])\n",
    "\n",
    "    return np.mean(r2), a, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96751e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "noiseCeiling = {}\n",
    "allA = []\n",
    "allP = []\n",
    "lab = []\n",
    "\n",
    "noiseCeiling['Global'], a, p = crossVal(pMathsDataFiltered, pMathsDataFiltered, 'Question', 'Answer', 'SubID')\n",
    "\n",
    "allA += a\n",
    "allP += p\n",
    "lab += [\"Global\"] * len(a)\n",
    "\n",
    "for (level, levelId), levelData in pMathsDataFiltered.groupby(['EdLevel', 'EdLevelId']):\n",
    "    cval, a, p = crossVal(levelData, pMathsDataFiltered, 'Question', 'Answer', 'SubID')\n",
    "    \n",
    "    noiseCeiling[level] = cval\n",
    "    noiseCeiling[levelId] = cval\n",
    "    allA += a\n",
    "    allP += p\n",
    "    lab += [level] * len(a)\n",
    "    \n",
    "noiseData = pd.DataFrame({\"Level\": lab, \"Slopes\": allA, \"N\": allP})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166927ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "noiseCeilingWordLevel = {}\n",
    "allA = []\n",
    "allP = []\n",
    "lab = []\n",
    "\n",
    "noiseCeilingWordLevel['Global'], a, p = crossVal(pMathsDataFiltered, pMathsDataFiltered, 'Question', 'Answer', 'SubID')\n",
    "\n",
    "allA += a\n",
    "allP += p\n",
    "lab += [\"Global\"] * len(a)\n",
    "\n",
    "for (levelId, levelData), level in zip(pMathsDataFiltered.groupby('PairLevel'), wordLevelOrder):\n",
    "    cval, a, p = crossVal(levelData, pMathsDataFiltered, 'Question', 'Answer', 'SubID')\n",
    "    \n",
    "    noiseCeilingWordLevel[level] = cval\n",
    "    noiseCeilingWordLevel[levelId] = cval\n",
    "    allA += a\n",
    "    allP += p\n",
    "    lab += [level] * len(a)\n",
    "    \n",
    "noiseDataWordLevel = pd.DataFrame({\"Level\": lab, \"Slopes\": allA, \"N\": allP})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46155d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(rf\"Overall noise ceiling: {noiseCeiling['Global']:.2f}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89a08fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.displot(noiseData, x=\"Slopes\", kind='kde', col=\"Level\", cut=0,\n",
    "                col_wrap=4, col_order=[\"Global\"]+edLevelOrder, facet_kws={'sharey':False})\n",
    "g.refline(x=0)\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0559919f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each fold, number of trials that were unique to the fold (pairs presented only to the left-over participant)\n",
    "ax = sns.boxplot(noiseData, x=\"N\", y=\"Level\", order=[\"Global\"]+edLevelOrder)\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9497fcd8",
   "metadata": {},
   "source": [
    "#### Correlation between rated similarity and our four categorical levels of predicted similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2bff1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pMathsDataAgg.groupby(\"CategoricalSim\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeab114f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kruskal-Wallis\n",
    "tmp = pMathsDataAgg.reset_index().pivot(index='Question', columns='CategoricalSim', values='Answer')\n",
    "stats.kruskal(tmp.Average, tmp.Closest, tmp.Furthest, tmp.Orthogonal, nan_policy='omit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e23819",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dunn\n",
    "posthoc_dunn(pMathsDataAgg, val_col=\"Answer\", group_col=\"CategoricalSim\", p_adjust=\"bonferroni\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee2511c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.boxplot(pMathsDataAgg, x=\"CategoricalSim\", y=\"Answer\", \n",
    "                 order=catSimOrder)\n",
    "ax.set(xlabel=\"Categorical levels of GloVe predicted similarities (cosine)\", ylabel=\"Distribution of human estimated similarity\")\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff3a858",
   "metadata": {},
   "source": [
    "#### Correlation between rated similarity and a continuous measure (cosine angle or Euclidean distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7edf36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantileCut(df, cols, q=100):\n",
    "    \n",
    "    def oneshot(df, col, q):\n",
    "        try:\n",
    "            quantiles = pd.DataFrame(pd.qcut(df[col], q=q))\n",
    "        except ValueError:\n",
    "            quantiles = pd.DataFrame(pd.qcut(df[col].rank(method='first'), q=q))\n",
    "        tmp = df.join(quantiles, rsuffix=\"_bins\")\n",
    "        means = tmp.groupby(col+'_bins').mean()\n",
    "        means = pd.DataFrame(means[col])\n",
    "        dff = tmp.join(means, on=col+'_bins', rsuffix='Bins')\n",
    "        dff.drop(columns=[col+'_bins'], inplace=True)\n",
    "        return dff\n",
    "    \n",
    "    if len(np.shape(cols)) == 0:\n",
    "        cols = np.reshape(cols, (len(cols)))\n",
    "\n",
    "    for col in cols:\n",
    "        df = oneshot(df, col, q)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268de517",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    assert not pMathsDataAgg_cop is None\n",
    "except:\n",
    "    pMathsDataAgg_cop = pMathsDataAgg.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25a7dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "pMathsDataAgg = quantileCut(pMathsDataAgg, ['EuclideanDistance', 'GloVeSimilarity', 'Answer'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4ce094",
   "metadata": {},
   "source": [
    "##### Cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8776202e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pMathsDataAgg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119fc060",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spearman's rank correlation analysis\n",
    "res = stats.spearmanr(pMathsDataAgg.Answer, pMathsDataAgg.GloVeSimilarity)\n",
    "display(Markdown(rf\"Spearman's $r_s$ coefficient: {res.statistic:.2f} (p = {res.pvalue:.2e})<br>$r_s^2$ = {res.statistic**2:.3f}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5cc5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = rankOLS(pMathsDataAgg.Answer, pMathsDataAgg.GloVeSimilarity)\n",
    "results = model.fit()\n",
    "results.summary2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7355dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = rankOLS(pMathsDataAgg.Answer, [pMathsDataAgg.GloVeSimilarity, pMathsDataAgg.MeanFreq])\n",
    "results = model.fit()\n",
    "results.summary2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691c3b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# article fig\n",
    "g = sns.JointGrid(pMathsDataAgg, x=\"GloVeSimilarityBins\", y=\"AnswerBins\", xlim=(-0.3389345948961322, 0.9453314081360167), ylim=(-0.10624661054156131, 5.090714332061703))\n",
    "g.plot_joint(sns.lineplot)\n",
    "g.plot_marginals(sns.histplot, kde=True)\n",
    "g.ax_joint.axvline(x=0, linestyle='--', color='.4')\n",
    "#g.set_axis_labels(\"GloVe similarity\", \"Human similarity\")\n",
    "g.set_axis_labels(\"\",\"\")\n",
    "# g.ax_joint.text(0.7, 0.5, f\"N = {len(pMathsDataAgg.Answer)}\\nSpearman's $r_s$ = {res.statistic:.2f}\\np < .001\", \n",
    "#                 horizontalalignment='center', verticalalignment='center', bbox={'edgecolor':'black', 'facecolor':'none'})\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(figWidth/1.2, figWidth*ratio)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7366f3",
   "metadata": {},
   "source": [
    "##### Cosine similarity in the 95% IQ only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922eab1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lb, ub = pMathsDataAgg_cop.GloVeSimilarity.quantile([.025, .975])\n",
    "iqPred = pMathsDataAgg_cop[(pMathsDataAgg_cop.GloVeSimilarity >= lb) & (pMathsDataAgg_cop.GloVeSimilarity <= ub)]\n",
    "iqPred = quantileCut(iqPred, ['Answer', 'GloVeSimilarity', 'EuclideanDistance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70fbb7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = stats.spearmanr(iqPred.AnswerBins, iqPred.GloVeSimilarityBins)\n",
    "display(Markdown(rf\"Spearman's $r_s$ coefficient: {res.statistic:.2f} (p = {res.pvalue:.2e})<br>$r_s^2$ = {res.statistic**2:.3f}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a36073",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = rankOLS(iqPred.AnswerBins, [iqPred.GloVeSimilarityBins, iqPred.MeanFreq])\n",
    "results = model.fit()\n",
    "results.summary2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a9fd1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.JointGrid(iqPred, x=\"GloVeSimilarityBins\", y=\"AnswerBins\")\n",
    "g.plot_joint(sns.lineplot)\n",
    "g.plot_marginals(sns.histplot, kde=True)\n",
    "g.set_axis_labels(\"GloVe predicted similarity (cosine)\", \"Average human judged similarity by item\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406c2892",
   "metadata": {},
   "source": [
    "##### Cosine similarity for negative predicted similarities only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5c3cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "negPred = pMathsDataAgg_cop[pMathsDataAgg_cop.GloVeSimilarity <= 0]\n",
    "negPred = quantileCut(negPred, ['Answer', 'GloVeSimilarity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d9d264",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = stats.spearmanr(negPred.AnswerBins, negPred.GloVeSimilarityBins)\n",
    "display(Markdown(rf\"Spearman's $r_s$ coefficient: {res.statistic:.2f} (p = {res.pvalue:.2e})<br>$r_s^2$ = {res.statistic**2:.3f}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706b383e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = rankOLS(negPred.AnswerBins, negPred.GloVeSimilarityBins)\n",
    "results = model.fit()\n",
    "results.summary2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7685ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "bic = results.bic\n",
    "display(Markdown(rf\"BIC = {bic}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782ca198",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.JointGrid(negPred, x=\"GloVeSimilarityBins\", y=\"AnswerBins\", height=11.7)\n",
    "g.plot_joint(sns.lineplot)\n",
    "g.plot_marginals(sns.histplot, kde=True)\n",
    "g.set_axis_labels(\"GloVe predicted similarity (cosine)\", \"Average human judged similarity by item\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ae2046",
   "metadata": {},
   "source": [
    "##### Euclidean distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba24c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = rankOLS(pMathsDataAgg.AnswerBins, pMathsDataAgg.EuclideanDistanceBins)\n",
    "results = model.fit()\n",
    "results.summary2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9b062a",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.JointGrid(pMathsDataAgg, x=\"EuclideanDistanceBins\", y=\"AnswerBins\", height=11.7)\n",
    "g.plot_joint(sns.lineplot)\n",
    "g.plot_marginals(sns.histplot, kde=True)\n",
    "g.set_axis_labels(\"GloVe predicted distance (Euclidean)\", \"Average human judged similarity by item\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cdc9c9c",
   "metadata": {},
   "source": [
    "##### Embedding pruning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a2fdd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune(humanSim, embeddings):\n",
    "    \"\"\"\n",
    "    implementation of the pruning algorithm described in Manrique, N. F., Bao, W., Herbelot, A., & Hasson, U. (2023). Enhancing Interpretability using Human Similarity Judgements to Prune Word Embeddings (arXiv:2310.10262). arXiv. http://arxiv.org/abs/2310.10262\n",
    "\n",
    "    \"\"\"\n",
    "    words = list(embeddings.index)\n",
    "    embeddings = embeddings.to_numpy()\n",
    "    nwords, nfeatures = embeddings.shape\n",
    "\n",
    "    humanSim = humanSim.to_numpy()\n",
    "\n",
    "    # Compute baseline Spearman’s Rho\n",
    "    modelSim = 1-pairwise_distances(embeddings, embeddings, metric='cosine')\n",
    "    baseline = stats.spearmanr(humanSim.flatten(), modelSim.flatten(), nan_policy='omit').statistic\n",
    "\n",
    "    # Rank features\n",
    "    diff = []\n",
    "    for i in range(nfeatures):\n",
    "        partial = np.delete(embeddings, i, axis=1)\n",
    "        partialSim = 1-pairwise_distances(partial, partial, metric='cosine')\n",
    "        rho = stats.spearmanr(humanSim.flatten(), partialSim.flatten(), nan_policy='omit').statistic\n",
    "        diff.append(baseline-rho)\n",
    "    featuresImportance = np.argsort(diff)[::-1]\n",
    "\n",
    "    # Construct pruned embeddings\n",
    "    a = []\n",
    "    for i in range(nfeatures):\n",
    "        toRemove = featuresImportance[i+1:]\n",
    "        partial = np.delete(embeddings, toRemove, axis=1)\n",
    "        partialSim = 1-pairwise_distances(partial, partial, metric='cosine')\n",
    "        rho = stats.spearmanr(humanSim.flatten(), partialSim.flatten(), nan_policy='omit').statistic\n",
    "        a.append(rho)\n",
    "    indexMax = np.argsort(a)[-1]\n",
    "    featuresToKeep = featuresImportance[:indexMax+1]\n",
    "\n",
    "    return featuresToKeep, a[indexMax]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0b1205",
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = []\n",
    "w2 = []\n",
    "sim = []\n",
    "for l in pMathsDataFiltered.itertuples():\n",
    "    if l.PresentationOrder == 'word1_word2':\n",
    "        w1.append(l.word1)\n",
    "        w2.append(l.word2)\n",
    "    else:\n",
    "        w1.append(l.word2)\n",
    "        w2.append(l.word1)\n",
    "    sim.append(l.Answer)\n",
    "pMathsDataOrder = pd.DataFrame({'word1': w1, 'word2': w2, 'answer': sim})\n",
    "pMathsDataOrderAgg = pMathsDataOrder.groupby(['word1', 'word2']).mean().reset_index()\n",
    "\n",
    "humanSim = pd.pivot(pMathsDataOrderAgg, index='word1', columns='word2', values='answer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c0d49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresToKeep, corr = prune(humanSim, vectors.loc[humanSim.index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18a5435",
   "metadata": {},
   "outputs": [],
   "source": [
    "newEmbeddings = vectors[[str(i+1) for i in featuresToKeep]].copy()\n",
    "newSim = pd.DataFrame(cosine_similarity(newEmbeddings)).set_index(vectors.index).rename(columns={i: vectors.index[i] for i in range(999)})\n",
    "newSimStack = newSim.stack().reset_index().rename(columns={'word': 'word1', 'level_1': 'word2', 0: 'PrunedSim'}).set_index(['word1','word2'])\n",
    "pMathsDataAggPruned = pMathsDataAgg.join(newSimStack, on=['word1', 'word2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfceeb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "newEmbeddings.to_csv('prunedEmbeddings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082e60a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pMathsDataAggPruned = quantileCut(pMathsDataAggPruned, ['PrunedSim'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafeeaff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spearman's rank correlation analysis\n",
    "res = stats.spearmanr(pMathsDataAggPruned.AnswerBins, pMathsDataAggPruned.PrunedSimBins)\n",
    "display(Markdown(rf\"Spearman's $r_s$ coefficient: {res.statistic:.2f} (p = {res.pvalue:.2e})<br>$r_s^2$ = {res.statistic**2:.3f}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009ec0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = rankOLS(pMathsDataAggPruned.AnswerBins, pMathsDataAggPruned.PrunedSimBins)\n",
    "results = model.fit()\n",
    "results.summary2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92c1248",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.JointGrid(pMathsDataAggPruned, x=\"PrunedSimBins\", y=\"AnswerBins\")\n",
    "g.plot_joint(sns.lineplot)\n",
    "g.plot_marginals(sns.histplot, kde=True)\n",
    "g.ax_joint.axvline(x=0, linestyle='--', color='.4')\n",
    "#g.set_axis_labels(\"GloVe similarity\", \"Human similarity\")\n",
    "g.set_axis_labels(\"\",\"\")\n",
    "# g.ax_joint.text(0.7, 0.5, f\"N = {len(pMathsDataAgg.Answer)}\\nSpearman's $r_s$ = {res.statistic:.2f}\\np < .001\", \n",
    "#                 horizontalalignment='center', verticalalignment='center', bbox={'edgecolor':'black', 'facecolor':'none'})\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(figWidth/1.2, figWidth*ratio)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5eee9d1",
   "metadata": {},
   "source": [
    "#### Quality of GloVe fit depending on education level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3869f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "nonMathsData = pd.read_csv('../Data/pairSim/English/pairSim_50_nonmaths.csv', encoding='utf-8', index_col='PairID')\n",
    "allData = pd.read_csv('../Data/pairSim/English/pairSim_50_all.csv', encoding='utf-8', index_col='PairID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5896640",
   "metadata": {},
   "outputs": [],
   "source": [
    "# global fit global corpus\n",
    "globalFit = pMathsDataFiltered.join(allData, on=\"Question\", lsuffix=\"_part\")\n",
    "model = rankOLS(globalFit.Answer,globalFit.Similarity)\n",
    "results = model.fit()\n",
    "results.summary2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be4534e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# global fit non-maths corpus\n",
    "nonmathsFit = pMathsDataFiltered.join(nonMathsData, on=\"Question\", lsuffix=\"_part\")\n",
    "model = rankOLS(nonmathsFit.Similarity, nonmathsFit.Answer)\n",
    "results = model.fit()\n",
    "results.summary2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55cdfcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# global fit maths corpus\n",
    "mathsFit = pMathsDataFiltered.join(stimData, on=\"Question\", lsuffix=\"_part\")\n",
    "model = rankOLS(mathsFit.Similarity, mathsFit.Answer)\n",
    "results = model.fit()\n",
    "results.summary2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177ee04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# education level\n",
    "\n",
    "mathsR = []\n",
    "nonMathsR = []\n",
    "allR = []\n",
    "edLevel = []\n",
    "\n",
    "for level, levelData in pMathsDataFiltered.groupby('EdLevelId'):\n",
    "    edLevel.append(int(level))\n",
    "    for sims, simList in zip([stimData, nonMathsData, allData], [mathsR, nonMathsR, allR]):\n",
    "        dat = levelData.join(sims, on=\"Question\", rsuffix=\"Sim\")\n",
    "        model = rankOLS(dat.Answer, dat.Similarity)\n",
    "        result = model.fit()\n",
    "        simList.append(result.rsquared)\n",
    "        \n",
    "        \n",
    "diffGloVeEdLevel = pd.DataFrame(index=edLevel, data={'Maths Corpus': mathsR, 'Non Maths Corpus': nonMathsR, 'All Corpora': allR})\n",
    "diffGloVeEdLevel = pd.DataFrame(diffGloVeEdLevel.stack()).rename(columns={0: 'Fit'})\n",
    "diffGloVeEdLevel = diffGloVeEdLevel.reset_index().rename(columns={'level_0': 'Level', 'level_1': 'Training Corpus'})\n",
    "diffGloVeEdLevel['Fit'] = np.array(diffGloVeEdLevel.Fit)*100\n",
    "diffGloVeEdLevel['NoiseCeiling'] = [noiseCeiling[x]*100 for x in diffGloVeEdLevel.Level]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07032892",
   "metadata": {},
   "outputs": [],
   "source": [
    "# level of acquisition of the pair\n",
    "\n",
    "mathsR = []\n",
    "nonMathsR = []\n",
    "allR = []\n",
    "wordLevel = []\n",
    "\n",
    "for level, levelData in pMathsDataFiltered.groupby('PairLevel'):\n",
    "    wordLevel.append(int(level))\n",
    "    for sims, simList in zip([stimData, nonMathsData, allData], [mathsR, nonMathsR, allR]):\n",
    "        dat = levelData.join(sims, on=\"Question\", rsuffix=\"Sim\")\n",
    "        model = rankOLS(dat.Answer, dat.Similarity)\n",
    "        result = model.fit()\n",
    "        simList.append(result.rsquared)\n",
    "        \n",
    "        \n",
    "diffGloVeWordLevel = pd.DataFrame(index=wordLevel, data={'Maths Corpus': mathsR, 'Non Maths Corpus': nonMathsR, 'All Corpora': allR})\n",
    "diffGloVeWordLevel = pd.DataFrame(diffGloVeWordLevel.stack()).rename(columns={0: 'Fit'})\n",
    "diffGloVeWordLevel = diffGloVeWordLevel.reset_index().rename(columns={'level_0': 'Level', 'level_1': 'Training Corpus'})\n",
    "diffGloVeWordLevel['Fit'] = np.array(diffGloVeWordLevel.Fit)*100\n",
    "diffGloVeWordLevel['NoiseCeiling'] = [noiseCeilingWordLevel[x]*100 for x in diffGloVeWordLevel.Level]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334294ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# article fig\n",
    "diffGloVeEdLevel['rank'] = diffGloVeEdLevel['Level'].rank(method='dense')-1\n",
    "ax = sns.pointplot(diffGloVeEdLevel, x='Level', y='Fit', hue='Training Corpus')\n",
    "sns.lineplot(diffGloVeEdLevel, x='rank', y='NoiseCeiling', ax=ax, linestyle='--', color='grey', sort=False, legend=False)\n",
    "ax.set(ylim=[0,55], ylabel='', xlabel='',\n",
    "       xticks=[i for i in range(len(edLevelOrder)-1)])\n",
    "ax.set_xticklabels(edLevelOrder[1:], rotation = 45, ha='right')\n",
    "leg = plt.legend()\n",
    "leg.remove()\n",
    "plt.grid(axis='x')\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(figWidth/1.4, ratio*figWidth)\n",
    "for item in ([ax.title, ax.xaxis.label, ax.yaxis.label] +\n",
    "             ax.get_xticklabels() + ax.get_yticklabels()):\n",
    "    item.set_fontsize(12)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438d7ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# article fig\n",
    "ax = sns.pointplot(diffGloVeWordLevel, x='Level', y='Fit', hue='Training Corpus')#, sort=False)\n",
    "sns.lineplot(diffGloVeWordLevel, x='Level', y='NoiseCeiling',legend=False, linestyle='--', color='grey', sort=False, ax=ax,\n",
    "            label='Noise ceiling')\n",
    "ax.set(ylim=[0,55], ylabel='', xlabel='',\n",
    "       xticks=[i for i in range(len(wordLevelOrder)-1)])\n",
    "# ax.set(ylim=[0,100], ylabel='% of explained variance', xlabel='Estimated level of acquisition of words of the pair',\n",
    "#        xticks=[i for i in range(len(wordLevelOrder))])\n",
    "ax.set_xticklabels(wordLevelOrder[:-1], rotation = 30, ha='right')\n",
    "leg = plt.legend()\n",
    "leg.remove()\n",
    "plt.grid(axis='x')\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(figWidth/1.4, ratio*figWidth)\n",
    "for item in ([ax.title, ax.xaxis.label, ax.yaxis.label] +\n",
    "             ax.get_xticklabels() + ax.get_yticklabels()):\n",
    "    item.set_fontsize(14)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4620082",
   "metadata": {},
   "source": [
    "## Optimisation of number of dimensions of GloVe vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c2e03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "GloVeDims = []\n",
    "\n",
    "indices = [i for i in range(1,50)] + [i for i in range(50,501,50)]\n",
    "\n",
    "for i in indices:\n",
    "    for corpus in [\"maths\", \"nonmaths\", \"all\"]:\n",
    "        dat = pd.read_csv(f'../Data/pairSim/English/pairSim_{i}_{corpus}.csv', encoding='utf-8')\n",
    "        dat['NumberDim'] = [i]*len(dat)\n",
    "        dat['TrainingCorpus'] = [corpus]*len(dat)\n",
    "        GloVeDims.append(dat)\n",
    "        \n",
    "GloVeDims = pd.concat(GloVeDims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35e16c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = []\n",
    "corpus = []\n",
    "nDims = []\n",
    "\n",
    "for (n, c), corpusData in GloVeDims.groupby(['NumberDim', 'TrainingCorpus']):\n",
    "        nDims.append(n)\n",
    "        dat = pMathsDataFiltered.join(corpusData.set_index('PairID'), on=\"Question\", rsuffix=\"Sim\")\n",
    "        corpus.append(c)\n",
    "        model = rankOLS(dat.Answer, dat.Similarity)\n",
    "        result = model.fit()\n",
    "        r.append(result.rsquared)\n",
    "        \n",
    "        \n",
    "GloVeDimsSubs = pd.DataFrame(data={'NumberDim': nDims, 'TrainingCorpus': corpus, 'Fit': np.array(r)*100})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efaab76",
   "metadata": {},
   "outputs": [],
   "source": [
    "GloVeDimsSubs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5e1c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# article fig\n",
    "ax = sns.lineplot(GloVeDimsSubs.loc[GloVeDimsSubs.TrainingCorpus == \"maths\"], x=\"NumberDim\", y=\"Fit\")\n",
    "ax.axhline(y=noiseCeiling['Global']*100, color='grey', linestyle='--')\n",
    "ax.set(xlabel=\"\", ylabel=\"\", ylim=[0,50])\n",
    "#ax.set(ylim=[0,100], ylabel=\"% of explained variance\", xlabel=\"Number of dimensions of GloVe vectors\")\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(figWidth/1.4, ratio*figWidth/1.4)\n",
    "for item in ([ax.title, ax.xaxis.label, ax.yaxis.label] +\n",
    "             ax.get_xticklabels() + ax.get_yticklabels()):\n",
    "    item.set_fontsize(10)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
